{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D7tqLMoKF6uq"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 5 - NCE LOSS VERSION\n",
    "------------\n",
    "\n",
    "The goal of this assignment is to train a Word2Vec skip-gram model over [Text8](http://mattmahoney.net/dc/textdata) data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explicacion de un skip-gram: [Word2Vec-skipgram](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)\n",
    "consiste en crear un \"concepto\" de cada palabra basado en la relación con las demás palabras del vocabulario, y luego poder usar ese concepto posteriormente, dado que tratamos con un sistema no supervisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "0K1ZyLn04QZf"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from matplotlib import pylab\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_nearest_embeddings_PCA(word,norm_embeddings,area=10):\n",
    "    \n",
    "    assert (word in dictionary), 'This word is not in the dictionary'\n",
    "    \n",
    "    word_id = dictionary[word]\n",
    "    print('ID for \"' + word +'\" is ' + str(word_id))\n",
    "\n",
    "    # Compute the similarity between selected word and all embeddings.\n",
    "    print('computing neighbors...')\n",
    "\n",
    "    # We use the cosine distance:\n",
    "    my_embedding = norm_embeddings[word_id]\n",
    "    S = np.matmul(my_embedding, np.transpose(norm_embeddings))\n",
    "    #np.reshape(tensor=similarity,shape=[vocabulary_size])  \n",
    "\n",
    "    words = []\n",
    "    nearest = (-S).argsort()[1:area+1] # del vector de probabilidades de vecindad toma los mayores MENOS ÉL MISMO\n",
    "    log = '\\tNearest %d to \"%s\":' % (area,word)\n",
    "    for k in range(area):\n",
    "        close_word = reverse_dictionary[nearest[k]]\n",
    "        words = words + [close_word]\n",
    "        log = '%s %s,' % (log, close_word)\n",
    "    print(log)\n",
    "    \n",
    "    #Incluyo la propia palabra para que se vea tambien en el dibujo\n",
    "    words = words + [word]\n",
    "    nearest = np.append(nearest,word_id)\n",
    "    #print(nearest)\n",
    "    #print(words)\n",
    "\n",
    "    #Funcion para pintar las proyecciones 2D\n",
    "    def plot2D(embeddings, labels):\n",
    "      assert embeddings.shape[0] >= len(labels), 'More labels than embeddings'\n",
    "      pylab.figure(figsize=(15,15))  # in inches\n",
    "      for i, label in enumerate(labels):\n",
    "        x, y = embeddings[i,:]\n",
    "        pylab.scatter(x, y)\n",
    "        pylab.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points',ha='right', va='bottom')\n",
    "      pylab.show()\n",
    "\n",
    "    print('projecting and plotting...')\n",
    "\n",
    "    #embeddings_subset = norm_embeddings[1:301, :] # da BUG\n",
    "    #embeddings_subset = norm_embeddings[initial_word:num_points+1, :]\n",
    "    #embeddings_subset = norm_embeddings #si calculo todos REVIENTA el ordenador el TSNE\n",
    "    embeddings_subset = norm_embeddings[nearest, :] #si calculo demasiado pocos REVIENTA también TSNE :-(\n",
    "    \n",
    "    #Calcular el TSNE (NO PORQUE FALLA)\n",
    "    #px = 30\n",
    "    #px = area\n",
    "    #tsne = TSNE(perplexity=px, n_components=2, init='pca', n_iter=5000)\n",
    "    #two_d_embeddings_tsne = tsne.fit_transform(embeddings_subset)\n",
    "    \n",
    "    #aplico PCA porque si funciona\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    two_d_embeddings_pca = pca.fit_transform(embeddings_subset)\n",
    "    print(\"\\tPCA variance ratio\",pca.explained_variance_ratio_)\n",
    "    \n",
    "    #Vamos a dibujar un rango de número de elementos \"area\" alrededor de la palabra\n",
    "    plot2D(two_d_embeddings_pca, words)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCjPJE944bkV"
   },
   "source": [
    "Download the data from the source website if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 14640,
     "status": "ok",
     "timestamp": 1445964482948,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "2f1ffade4c9f20de",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "RJ-o3UBUFtCw",
    "outputId": "c4ec222c-80b5-4298-e635-93ca9f79c3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified text8.zip\n"
     ]
    }
   ],
   "source": [
    "url = 'http://mattmahoney.net/dc/'\n",
    "\n",
    "def maybe_download(filename, expected_bytes):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  if not os.path.exists(filename):\n",
    "    filename, _ = urlretrieve(url + filename, filename)\n",
    "  statinfo = os.stat(filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified %s' % filename)\n",
    "  else:\n",
    "    print(statinfo.st_size)\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + filename + '. Can you get to it with a browser?')\n",
    "  return filename\n",
    "\n",
    "filename = maybe_download('text8.zip', 31344016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zqz3XiqI4mZT"
   },
   "source": [
    "Read the data into a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 28844,
     "status": "ok",
     "timestamp": 1445964497165,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "2f1ffade4c9f20de",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "Mvf09fjugFU_",
    "outputId": "e3a928b4-1645-4fe8-be17-fcf47de5716d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size 17005207\n"
     ]
    }
   ],
   "source": [
    "def read_data(filename):\n",
    "  \"\"\"Extract the first file enclosed in a zip file as a list of words\"\"\"\n",
    "  with zipfile.ZipFile(filename) as f:\n",
    "    data = tf.compat.as_str(f.read(f.namelist()[0])).split()\n",
    "  return data\n",
    "  \n",
    "words = read_data(filename)\n",
    "print('Data size %d' % len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zdw6i4F8glpp"
   },
   "source": [
    "Build the dictionary and replace rare words with UNK token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "def how_long(f, *args):\n",
    "    #medir el tiempo que tarda f\n",
    "    t1 = time.time()\n",
    "    res = f(*args)\n",
    "    t2 = time.time()\n",
    "    print (\"tiempo utilizado = \",t2-t1)\n",
    "    #return res, t2-t1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 28849,
     "status": "ok",
     "timestamp": 1445964497178,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "2f1ffade4c9f20de",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "gAL1EECXeZsD",
    "outputId": "3fb4ecd1-df67-44b6-a2dc-2291730970b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo utilizado =  23.3996648788\n",
      "Most common words (+UNK) [['UNK', 418391], ('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764)]\n",
      "Sample data [5239, 3084, 12, 6, 195, 2, 3137, 46, 59, 156]\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 50000\n",
    "\n",
    "def build_dataset(words):\n",
    "  #inicializa el array de contadores de palabras (frecuencias)\n",
    "  count = [['UNK', -1]]\n",
    "  #cuenta las 50000 palabras más comunes\n",
    "  count.extend(collections.Counter(words).most_common(vocabulary_size - 1))\n",
    "  #inicializa un diccionario del vocabulario, va a crear pares palabra - ID, para tratar con números\n",
    "  #y asigna los id por orden de frecuencia de más a menos\n",
    "  #RESERVA ID=0 para los \"OTROS POCO FRECUENTES\" que llama \"UNK\"\n",
    "  dictionary = dict()\n",
    "  for word, _ in count:\n",
    "    dictionary[word] = len(dictionary)\n",
    "  #inicializa y crea una lista de ID equivalente al dataset \"words\" reemplazando cada palabra por su ID\n",
    "  #y de paso va apuntando los UNK para rellenar la frecuencia\n",
    "  data = list()\n",
    "  unk_count = 0\n",
    "  for word in words:\n",
    "    if word in dictionary:\n",
    "      index = dictionary[word]\n",
    "    else:\n",
    "      index = 0  # dictionary['UNK']\n",
    "      unk_count = unk_count + 1\n",
    "    data.append(index)\n",
    "  #apunta el dato final de cuantas palabras raras hay (frecuencia de palabras raras)\n",
    "  count[0][1] = unk_count\n",
    "  #crea un diccionario al revés, es decir, donde el ID es la clave y la palabra es el valor\n",
    "  reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys())) \n",
    "  return data, count, dictionary, reverse_dictionary\n",
    "\n",
    "data, count, dictionary, reverse_dictionary = how_long(build_dataset,words)\n",
    "print('Most common words (+UNK)', count[:5])\n",
    "print('Sample data', data[:10])\n",
    "del words  # Hint to reduce memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lFwoyygOmWsL"
   },
   "source": [
    "Function to generate a training batch for the skip-gram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 113,
     "status": "ok",
     "timestamp": 1445964901989,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "2f1ffade4c9f20de",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "w9APjA-zmfjV",
    "outputId": "67cccb02-cdaf-4e47-d489-43bcc8d57bb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first']\n",
      "\n",
      "with num_skips = 2 and skip_window = 1:\n",
      "    batch: ['originated', 'originated', 'as', 'as', 'a', 'a', 'term', 'term']\n",
      "    labels: ['anarchism', 'as', 'a', 'originated', 'term', 'as', 'a', 'of']\n",
      "\n",
      "with num_skips = 4 and skip_window = 2:\n",
      "    batch: ['as', 'as', 'as', 'as', 'a', 'a', 'a', 'a']\n",
      "    labels: ['originated', 'term', 'a', 'anarchism', 'of', 'term', 'as', 'originated']\n"
     ]
    }
   ],
   "source": [
    "data_index = 0\n",
    "\n",
    "#batch_size, tamaño del lote a meter en la red neural para aprender\n",
    "#skip_window, tamaño del lado derecho e izquierdo de la ventana alrededor de una palabra (es simétrica)\n",
    "#num_skips, distancia de palabra adyacente que va a tomar como etiqueta \n",
    "\n",
    "def generate_batch_skipgram(batch_size, num_skips, skip_window):\n",
    "  global data_index #indicador de por donde va recorriendo los datos de aprendizaje\n",
    "  \n",
    "  #comprobaciones\n",
    "  assert batch_size % num_skips == 0 #el tamaño del lote debe ser divisible por los descartes\n",
    "  assert num_skips <= 2 * skip_window\n",
    "\n",
    "  #variables a usar\n",
    "  batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "  labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "  span = 2 * skip_window + 1 # [ skip_window target skip_window ] \n",
    "    #se mira alrededor de la palabra el ancho de ventana (2*ventana y +1 la palabra en medio)\n",
    "  buffer = collections.deque(maxlen=span) #reserva variable vacía tipo \"deque\" para almacenar \n",
    "                                            #una ventana que rodea una palabra\n",
    "  \n",
    "  #rellena una ventana inicial desde donde se quedo\n",
    "  for _ in range(span):\n",
    "    buffer.append(data[data_index])\n",
    "    data_index = (data_index + 1) % len(data) #circular\n",
    "\n",
    "  #rellena un lote y a cada palabra le pone de objetivo las palabras adyacentes a distancia \n",
    "    #num_skips o menor delante y detrás\n",
    "  #siempre por pares, pero tomando RANDOM de esa ventana, no en orden\n",
    "  for i in range(batch_size // num_skips):\n",
    "    target = skip_window  # target label at the center of the buffer\n",
    "    targets_to_avoid = [ skip_window ]\n",
    "    for j in range(num_skips):\n",
    "      #monta todo este lío para que no vayan en orden exacto las palabras...\n",
    "      while target in targets_to_avoid:\n",
    "        target = random.randint(0, span - 1)\n",
    "      targets_to_avoid.append(target)\n",
    "      batch[i * num_skips + j] = buffer[skip_window]\n",
    "      labels[i * num_skips + j, 0] = buffer[target]\n",
    "    \n",
    "    #pasa a la siguiente ventana\n",
    "    buffer.append(data[data_index])\n",
    "    data_index = (data_index + 1) % len(data)\n",
    "    \n",
    "  return batch, labels\n",
    "\n",
    "#Ejecucion de ejemplo para las primeras ocho palabras del diccionario (un lote de ocho)\n",
    "\n",
    "lote = 8\n",
    "print('data:', [reverse_dictionary[di] for di in data[:lote]])\n",
    "\n",
    "for num_skips, skip_window in [(2, 1), (4, 2)]:\n",
    "    data_index = 0\n",
    "    batch, labels = generate_batch_skipgram(batch_size=lote, num_skips=num_skips, skip_window=skip_window)\n",
    "    print('\\nwith num_skips = %d and skip_window = %d:' % (num_skips, skip_window))\n",
    "    print('    batch:', [reverse_dictionary[bi] for bi in batch])\n",
    "    print('    labels:', [reverse_dictionary[li] for li in labels.reshape(lote)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ofd1MbBuwiva"
   },
   "source": [
    "# Train a skip-gram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "8pQKsV4Vwlzy"
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# DECLARACION SKIP-GRAM\n",
    "##################\n",
    "\n",
    "batch_size = 128 #Lotes de entrenamiento.\n",
    "\n",
    "embedding_size = 128 # Dimension of the embedding vector. Las features de cada palabra que la distinguen.\n",
    "skip_window = 1 # How many words to consider left and right. Semiventana, al final ventana de 3.\n",
    "                # Es poco debería ser mayor pero más procesamiento también.\n",
    "num_skips = 2 # How many times to reuse an input to generate a label. \n",
    "                #Normalmente ancho-ventana - 1 (3-1 = 2). O 2*skip_window\n",
    "\n",
    "# We pick a random validation set to sample nearest neighbors. here we limit the\n",
    "# validation samples to the words that have a low numeric ID, which by construction are also the most frequent. \n",
    "# Va a utilizar como validationSet las palabras más comunes del diccionario (las del principio)\n",
    "valid_size = 16 # Random set of words to evaluate similarity on. Escoge 16 para validacion.\n",
    "valid_window = 100 # Only pick dev samples in the head of the distribution. Las escoge de entre las 100 primeras.\n",
    "valid_examples = np.array(random.sample(range(valid_window), valid_size))\n",
    "\n",
    "# CURIOSAMENTE NO TOMA UN TEST SET ESTA VEZ, LE DA IGUAL\n",
    "\n",
    "num_sampled = 64 # Number of negative examples to sample. Muestras aleatorias de entre el lote \n",
    "                                                        #que sirven para calcular LOSS.\n",
    "\n",
    "learning_rate = 1.0\n",
    "\n",
    "graphSG_NCE = tf.Graph()\n",
    "\n",
    "with graphSG_NCE.as_default(), tf.device('/cpu:0'):\n",
    "\n",
    "  # Input data.\n",
    "  train_dataset = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "  train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "  valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "  \n",
    "  # Variables y su inicializacion.\n",
    "       #CONCEPTO-FEATURES DE UNA PALABRA (primer layer):\n",
    "  embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0)) \n",
    "      #RELACION CON OTROS CONCEPTOS (segundo layer):\n",
    "  softmax_weights = tf.Variable(tf.truncated_normal([vocabulary_size, embedding_size],stddev=1.0 / math.sqrt(embedding_size)))\n",
    "  softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "  \n",
    "  # Model.\n",
    "  # Look up embeddings for inputs.\n",
    "  embed = tf.nn.embedding_lookup(embeddings, train_dataset) #Toma de los conceptos las líneas que corresponden \n",
    "                                                            #al lote de turno (por ID)\n",
    "  # Compute the softmax loss, using a sample of the negative labels each time.\n",
    "  loss = tf.reduce_mean(\n",
    "            tf.nn.nce_loss(softmax_weights, softmax_biases, embed, train_labels, num_sampled, vocabulary_size))\n",
    "        #Combina cada conceptos con las relaciones y obtiene la probabilidad de vecindad de las demás palabras del diccionario\n",
    "        #luego compara esa vecindad probable con las etiquetas para num_sampled aleatorias y saca la pérdida\n",
    "\n",
    "  #At inference time, you can compute full softmax probabilities for each word (referred to one word) with the expression \n",
    "  #tf.nn.softmax(tf.matmul(one_embed, tf.transpose(softmax_weights)) + softmax_biases).\n",
    "        \n",
    "  # Optimizer.\n",
    "  # Note: The optimizer will optimize the softmax_weights AND the embeddings.\n",
    "  # This is because the embeddings are defined as a variable quantity and the\n",
    "  # optimizer's `minimize` method will by default modify all variable quantities \n",
    "  # that contribute to the tensor it is passed.\n",
    "  # See docs on `tf.train.Optimizer.minimize()` for more details.\n",
    "  optimizer = tf.train.AdagradOptimizer(learning_rate).minimize(loss)\n",
    "  \n",
    "  # Compute the similarity between minibatch examples and all embeddings.\n",
    "  # We use the cosine distance:\n",
    "  norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "  normalized_embeddings = embeddings / norm\n",
    "  valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n",
    "  similarity = tf.matmul(valid_embeddings, tf.transpose(normalized_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### OJO Usa un optimizador de gradiente adaptativo:\n",
    "[Adagrad](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 23
      },
      {
       "item_id": 48
      },
      {
       "item_id": 61
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 436189,
     "status": "ok",
     "timestamp": 1445965429787,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "2f1ffade4c9f20de",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "1bQFGceBxrWW",
    "outputId": "5ebd6d9a-33c6-4bcd-bf6d-252b0b6055e4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "step 0\t0s\tAverage loss: 299.176697\n",
      "\tNearest to no: mannerism, erectus, acclaimed, lecturers, mcleod, cutlery, codenamed, goidelic,\n",
      "\tNearest to more: uke, leitch, belle, procol, remastered, recommendation, weeping, kansas,\n",
      "\tNearest to the: convert, bust, dauphin, duopoly, lynda, frogs, amplifiers, currently,\n",
      "\tNearest to their: afloat, cathal, yokoi, sung, etiquette, corrected, intolerable, esb,\n",
      "\tNearest to that: eyewitnesses, ideation, mural, gale, reader, arian, breakdancing, teborg,\n",
      "\tNearest to also: futile, nutritious, phrygia, enroll, buffalo, fremantle, melancholy, zia,\n",
      "\tNearest to than: apes, cranberry, independently, addiction, separatist, ambience, prefects, entendre,\n",
      "\tNearest to other: geckos, liliales, shape, add, tanakh, sacrifice, uniformity, decorator,\n",
      "\tNearest to world: persian, encloses, hormonal, fu, detritus, aided, arden, mutable,\n",
      "\tNearest to this: petite, nom, paton, discouraged, tended, alsos, organised, coloration,\n",
      "\tNearest to these: farley, exclaimed, needlessly, wine, dorsal, ornament, levellers, mpr,\n",
      "\tNearest to but: circumcising, galaxies, kinship, valentinus, kimmel, looping, conferencing, tuscan,\n",
      "\tNearest to at: altarpiece, blend, gielgud, intellectualism, jaffe, engrailed, enumerative, beggars,\n",
      "\tNearest to for: loneliness, electing, barrows, lodgings, unceasing, capacitor, mersenne, urls,\n",
      "\tNearest to it: gambeson, chamber, audubon, chew, isometry, annotations, rector, khrushchev,\n",
      "\tNearest to nine: reverted, conciliar, paulette, mentat, hieroglyph, mona, reciprocate, joking,\n",
      "step 2000\t8s\tAverage loss: 111.050396\n",
      "step 4000\t16s\tAverage loss: 51.275638\n",
      "step 6000\t23s\tAverage loss: 32.420320\n",
      "step 8000\t31s\tAverage loss: 23.255244\n",
      "step 10000\t38s\tAverage loss: 17.531285\n",
      "\tNearest to no: and, who, reviewing, lecturers, expropriation, prohibition, forcible, gimme,\n",
      "\tNearest to more: hl, uke, licensing, linkages, snowfalls, slump, ratification, svenska,\n",
      "\tNearest to the: a, its, his, this, an, their, some, any,\n",
      "\tNearest to their: his, its, the, s, this, portsmouth, a, kerouac,\n",
      "\tNearest to that: which, this, who, it, excepted, however, there, repairs,\n",
      "\tNearest to also: which, not, who, been, it, and, now, that,\n",
      "\tNearest to than: heresies, separatist, vrije, satirizes, cornerback, zar, photosynthetic, daytime,\n",
      "\tNearest to other: many, palliative, marguerite, expressway, verse, deposition, bckgr, athens,\n",
      "\tNearest to world: hitting, ppm, neq, db, bargaining, differentiation, blackface, pl,\n",
      "\tNearest to this: any, a, its, the, which, it, that, his,\n",
      "\tNearest to these: their, are, many, chords, yankovic, chubut, were, marr,\n",
      "\tNearest to but: is, while, candidate, are, abner, bequest, was, elect,\n",
      "\tNearest to at: and, in, for, with, from, by, on, of,\n",
      "\tNearest to for: with, of, from, and, at, in, to, as,\n",
      "\tNearest to it: he, there, not, this, they, that, who, a,\n",
      "\tNearest to nine: eight, seven, five, six, four, two, three, zero,\n",
      "step 12000\t46s\tAverage loss: 13.845319\n",
      "step 14000\t54s\tAverage loss: 11.729144\n",
      "step 16000\t62s\tAverage loss: 9.662403\n",
      "step 18000\t69s\tAverage loss: 8.584011\n",
      "step 20000\t77s\tAverage loss: 7.872825\n",
      "\tNearest to no: it, and, a, he, which, this, there, but,\n",
      "\tNearest to more: less, hl, spontaneity, lapland, snowfalls, so, beauvoir, lund,\n",
      "\tNearest to the: its, their, a, this, his, any, some, an,\n",
      "\tNearest to their: its, his, her, the, any, some, a, these,\n",
      "\tNearest to that: which, when, however, but, it, this, also, then,\n",
      "\tNearest to also: now, which, often, not, who, been, sometimes, still,\n",
      "\tNearest to than: or, with, over, for, while, firms, and, vrije,\n",
      "\tNearest to other: many, these, some, such, bellum, various, officeholders, gemological,\n",
      "\tNearest to world: pune, millionaires, ppm, ftc, bataan, gainsborough, deepwater, neq,\n",
      "\tNearest to this: it, the, a, which, any, its, some, that,\n",
      "\tNearest to these: some, many, all, such, several, which, the, other,\n",
      "\tNearest to but: however, and, while, if, which, was, although, is,\n",
      "\tNearest to at: in, from, with, and, between, during, on, including,\n",
      "\tNearest to for: in, with, against, of, and, during, from, under,\n",
      "\tNearest to it: he, there, this, which, they, but, no, who,\n",
      "\tNearest to nine: eight, seven, six, four, five, three, zero, one,\n",
      "step 22000\t85s\tAverage loss: 7.186727\n",
      "step 24000\t93s\tAverage loss: 6.835308\n",
      "step 26000\t100s\tAverage loss: 6.803787\n",
      "step 28000\t107s\tAverage loss: 6.134130\n",
      "step 30000\t115s\tAverage loss: 6.329924\n",
      "\tNearest to no: it, any, still, a, this, and, another, each,\n",
      "\tNearest to more: less, most, rather, so, circuses, used, very, hinder,\n",
      "\tNearest to the: its, their, his, this, any, a, another, her,\n",
      "\tNearest to their: its, his, the, her, some, any, each, these,\n",
      "\tNearest to that: which, however, but, what, when, this, because, although,\n",
      "\tNearest to also: now, often, sometimes, still, which, usually, been, therefore,\n",
      "\tNearest to than: while, but, much, with, vrije, for, or, over,\n",
      "\tNearest to other: various, some, these, many, such, different, shahi, including,\n",
      "\tNearest to world: millionaires, ppm, pune, bataan, yamato, neq, snowfalls, abakan,\n",
      "\tNearest to this: it, which, any, the, a, some, its, another,\n",
      "\tNearest to these: some, many, several, other, such, various, all, there,\n",
      "\tNearest to but: however, although, while, when, and, which, if, that,\n",
      "\tNearest to at: in, on, from, and, during, when, under, for,\n",
      "\tNearest to for: in, with, of, at, and, against, without, through,\n",
      "\tNearest to it: he, there, they, she, this, not, which, no,\n",
      "\tNearest to nine: eight, seven, six, five, four, three, zero, one,\n",
      "step 32000\t123s\tAverage loss: 5.921430\n",
      "step 34000\t130s\tAverage loss: 5.874442\n",
      "step 36000\t138s\tAverage loss: 5.815895\n",
      "step 38000\t146s\tAverage loss: 5.318385\n",
      "step 40000\t153s\tAverage loss: 5.537354\n",
      "\tNearest to no: any, a, another, still, or, it, this, the,\n",
      "\tNearest to more: less, most, so, rather, very, circuses, kushan, oplus,\n",
      "\tNearest to the: its, a, their, any, this, his, each, her,\n",
      "\tNearest to their: its, his, her, the, any, some, each, these,\n",
      "\tNearest to that: which, what, however, this, when, but, because, now,\n",
      "\tNearest to also: now, often, sometimes, still, generally, usually, which, therefore,\n",
      "\tNearest to than: or, but, while, abv, vrije, much, no, hiroshima,\n",
      "\tNearest to other: various, some, many, including, different, subscripts, these, human,\n",
      "\tNearest to world: abakan, yamato, propounded, solent, endomorphisms, fluffy, pune, plaza,\n",
      "\tNearest to this: the, which, any, it, that, its, some, another,\n",
      "\tNearest to these: some, many, several, both, such, all, various, which,\n",
      "\tNearest to but: however, and, although, while, when, where, only, though,\n",
      "\tNearest to at: during, in, on, under, for, when, through, from,\n",
      "\tNearest to for: of, in, against, on, without, at, with, during,\n",
      "\tNearest to it: he, she, there, they, this, which, still, however,\n",
      "\tNearest to nine: eight, six, seven, five, four, zero, three, two,\n",
      "step 42000\t161s\tAverage loss: 5.374537\n",
      "step 44000\t169s\tAverage loss: 5.308727\n",
      "step 46000\t177s\tAverage loss: 5.353649\n",
      "step 48000\t184s\tAverage loss: 5.037149\n",
      "step 50000\t192s\tAverage loss: 5.220352\n",
      "\tNearest to no: another, any, a, still, it, asymptotes, or, procurator,\n",
      "\tNearest to more: less, most, very, too, rather, so, oplus, kushan,\n",
      "\tNearest to the: its, their, a, his, this, any, each, some,\n",
      "\tNearest to their: its, his, her, the, any, some, both, several,\n",
      "\tNearest to that: which, however, what, where, when, but, because, this,\n",
      "\tNearest to also: now, often, sometimes, still, generally, usually, which, therefore,\n",
      "\tNearest to than: or, much, and, but, while, dhamma, vrije, hiroshima,\n",
      "\tNearest to other: various, different, some, many, these, including, subscripts, like,\n",
      "\tNearest to world: endomorphisms, yamato, gisela, abakan, uat, plaza, goo, pune,\n",
      "\tNearest to this: which, it, the, another, some, itself, any, that,\n",
      "\tNearest to these: some, various, many, several, both, such, different, those,\n",
      "\tNearest to but: however, when, although, though, while, and, if, where,\n",
      "\tNearest to at: in, during, for, on, within, under, from, through,\n",
      "\tNearest to for: at, of, and, against, including, without, during, through,\n",
      "\tNearest to it: he, she, there, they, this, still, now, not,\n",
      "\tNearest to nine: six, seven, eight, zero, three, four, five, one,\n",
      "step 52000\t200s\tAverage loss: 5.267979\n",
      "step 54000\t208s\tAverage loss: 5.170384\n",
      "step 56000\t215s\tAverage loss: 5.127162\n",
      "step 58000\t223s\tAverage loss: 5.207370\n",
      "step 60000\t230s\tAverage loss: 5.083515\n",
      "\tNearest to no: any, another, a, and, baralong, this, there, it,\n",
      "\tNearest to more: less, most, rather, very, too, bak, circuses, so,\n",
      "\tNearest to the: its, their, any, a, his, this, each, another,\n",
      "\tNearest to their: its, his, her, the, whose, your, several, some,\n",
      "\tNearest to that: which, what, this, however, where, but, usually, when,\n",
      "\tNearest to also: now, sometimes, often, still, usually, generally, therefore, never,\n",
      "\tNearest to than: or, and, but, much, since, over, gopher, dhamma,\n",
      "\tNearest to other: various, different, many, some, physical, like, subscripts, others,\n",
      "\tNearest to world: goo, yamato, abakan, mccay, gisela, endomorphisms, post, plaza,\n",
      "\tNearest to this: it, which, the, what, that, another, some, any,\n",
      "\tNearest to these: some, many, several, both, various, all, such, those,\n",
      "\tNearest to but: however, although, and, when, while, like, though, if,\n",
      "\tNearest to at: in, during, within, near, for, on, through, after,\n",
      "\tNearest to for: including, without, of, in, and, against, or, at,\n",
      "\tNearest to it: he, she, there, this, still, they, now, usually,\n",
      "\tNearest to nine: eight, six, seven, four, five, zero, three, one,\n",
      "step 62000\t238s\tAverage loss: 4.841391\n",
      "step 64000\t246s\tAverage loss: 4.796774\n",
      "step 66000\t253s\tAverage loss: 5.112652\n",
      "step 68000\t260s\tAverage loss: 4.948737\n",
      "step 70000\t268s\tAverage loss: 4.825269\n",
      "\tNearest to no: any, another, and, a, little, there, baralong, or,\n",
      "\tNearest to more: less, most, rather, too, very, bak, smaller, spontaneity,\n",
      "\tNearest to the: its, their, any, a, this, each, another, his,\n",
      "\tNearest to their: its, his, her, the, my, any, our, your,\n",
      "\tNearest to that: which, what, however, this, actually, where, usually, but,\n",
      "\tNearest to also: now, sometimes, often, still, generally, therefore, usually, never,\n",
      "\tNearest to than: or, but, and, while, since, dhamma, vrije, baralong,\n",
      "\tNearest to other: various, different, many, including, subscripts, individual, some, others,\n",
      "\tNearest to world: post, gisela, vos, however, foolish, yamato, savanna, u,\n",
      "\tNearest to this: which, it, another, the, what, that, itself, any,\n",
      "\tNearest to these: many, some, such, several, various, different, those, are,\n",
      "\tNearest to but: however, although, and, while, when, though, which, since,\n",
      "\tNearest to at: during, within, near, in, through, on, for, after,\n",
      "\tNearest to for: including, against, without, of, in, and, on, while,\n",
      "\tNearest to it: he, she, there, they, this, still, which, we,\n",
      "\tNearest to nine: eight, six, seven, five, four, zero, three, two,\n",
      "step 72000\t275s\tAverage loss: 4.854622\n",
      "step 74000\t283s\tAverage loss: 4.831809\n",
      "step 76000\t291s\tAverage loss: 5.054570\n",
      "step 78000\t298s\tAverage loss: 4.862725\n",
      "step 80000\t306s\tAverage loss: 4.924915\n",
      "\tNearest to no: any, another, baralong, little, still, this, it, there,\n",
      "\tNearest to more: less, most, rather, very, too, smaller, even, larger,\n",
      "\tNearest to the: their, its, a, this, another, any, each, his,\n",
      "\tNearest to their: its, his, her, the, our, my, your, several,\n",
      "\tNearest to that: which, however, what, where, when, this, instead, actually,\n",
      "\tNearest to also: now, sometimes, often, still, therefore, usually, which, thus,\n",
      "\tNearest to than: while, or, and, but, much, since, boney, even,\n",
      "\tNearest to other: various, different, many, individual, others, local, subscripts, bak,\n",
      "\tNearest to world: time, gisela, endomorphisms, yamato, foolish, ballpark, post, abakan,\n",
      "\tNearest to this: it, itself, which, another, the, what, any, some,\n",
      "\tNearest to these: many, several, some, various, such, those, both, all,\n",
      "\tNearest to but: however, although, while, and, though, since, when, has,\n",
      "\tNearest to at: during, in, within, on, under, through, for, with,\n",
      "\tNearest to for: against, including, without, in, at, of, on, during,\n",
      "\tNearest to it: he, she, there, this, they, itself, we, thus,\n",
      "\tNearest to nine: eight, seven, five, six, four, zero, three, two,\n",
      "step 82000\t313s\tAverage loss: 4.890750\n",
      "step 84000\t320s\tAverage loss: 4.855169\n",
      "step 86000\t328s\tAverage loss: 4.797755\n",
      "step 88000\t335s\tAverage loss: 4.722224\n",
      "step 90000\t342s\tAverage loss: 4.823693\n",
      "\tNearest to no: any, another, little, it, a, there, only, baralong,\n",
      "\tNearest to more: less, most, very, too, rather, particularly, smaller, extremely,\n",
      "\tNearest to the: its, their, any, each, a, this, another, his,\n",
      "\tNearest to their: its, his, her, our, my, the, your, whose,\n",
      "\tNearest to that: which, however, what, actually, instead, therefore, because, usually,\n",
      "\tNearest to also: now, often, sometimes, still, therefore, generally, usually, thus,\n",
      "\tNearest to than: or, and, much, while, but, since, less, from,\n",
      "\tNearest to other: various, different, individual, local, traditional, many, physical, others,\n",
      "\tNearest to world: yamato, time, gisela, endomorphisms, goo, biplane, abakan, axles,\n",
      "\tNearest to this: it, itself, another, which, the, any, what, some,\n",
      "\tNearest to these: many, some, several, instead, both, various, certain, such,\n",
      "\tNearest to but: however, although, and, while, since, though, which, until,\n",
      "\tNearest to at: during, in, near, under, through, on, within, with,\n",
      "\tNearest to for: against, of, including, without, in, with, when, during,\n",
      "\tNearest to it: he, she, there, this, they, itself, which, then,\n",
      "\tNearest to nine: eight, seven, six, five, four, zero, three, two,\n",
      "step 92000\t350s\tAverage loss: 4.775305\n",
      "step 94000\t357s\tAverage loss: 4.661494\n",
      "step 96000\t364s\tAverage loss: 4.778921\n",
      "step 98000\t371s\tAverage loss: 4.656288\n",
      "step 100000\t378s\tAverage loss: 4.736856\n",
      "\tNearest to no: another, any, little, only, every, baralong, accountant, or,\n",
      "\tNearest to more: less, most, very, too, particularly, rather, so, larger,\n",
      "\tNearest to the: its, their, his, a, each, any, this, whose,\n",
      "\tNearest to their: his, its, her, our, the, your, my, whose,\n",
      "\tNearest to that: which, however, what, actually, when, itself, because, where,\n",
      "\tNearest to also: now, still, sometimes, often, generally, therefore, usually, never,\n",
      "\tNearest to than: or, while, but, and, since, way, dhamma, much,\n",
      "\tNearest to other: various, individual, different, others, traditional, including, many, local,\n",
      "\tNearest to world: yamato, gisela, however, abakan, time, u, kaufmann, ballpark,\n",
      "\tNearest to this: itself, which, it, another, every, the, what, each,\n",
      "\tNearest to these: many, some, several, various, certain, such, instead, both,\n",
      "\tNearest to but: however, and, although, while, though, when, since, did,\n",
      "\tNearest to at: during, in, on, within, under, with, near, through,\n",
      "\tNearest to for: without, of, including, when, against, on, while, with,\n",
      "\tNearest to it: he, she, this, there, they, itself, what, usually,\n",
      "\tNearest to nine: eight, seven, six, four, five, zero, three, one,\n",
      "End.\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# EJECUCION SKIP-GRAM\n",
    "##################\n",
    "\n",
    "num_steps = 100001\n",
    "loss_report_interval = 2000\n",
    "similarity_report_interval = 10000\n",
    "top_k = 8 # number of nearest neighbors a mostrar en el informe de similitud\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "with tf.Session(graph=graphSG_NCE) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  average_loss = 0\n",
    "\n",
    "  # iterar\n",
    "  for step in range(num_steps):\n",
    "    batch_data, batch_labels = generate_batch_skipgram(batch_size, num_skips, skip_window)\n",
    "    feed_dict = {train_dataset : batch_data, train_labels : batch_labels}\n",
    "    _, L = session.run([optimizer, loss], feed_dict=feed_dict)\n",
    "    average_loss += L\n",
    "\n",
    "    # mostar la perdida media de un intervalo\n",
    "    if step % loss_report_interval == 0:\n",
    "      t2 = time.time()\n",
    "      if step > 0:\n",
    "        average_loss = average_loss / loss_report_interval\n",
    "      # The average loss is an estimate of the loss over the last loss_report_interval batches.\n",
    "      print('step %d\\t%ds\\tAverage loss: %f' % (step,t2-t1, average_loss))\n",
    "      average_loss = 0\n",
    "    \n",
    "    # mostrar la similitud alcanzada en un intervalo\n",
    "    # note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "    if step % similarity_report_interval == 0:\n",
    "      sim = similarity.eval() #tomar la variable calculada de similitud\n",
    "      for i in range(valid_size):\n",
    "        valid_word = reverse_dictionary[valid_examples[i]]\n",
    "        nearest = (-sim[i, :]).argsort()[1:top_k+1] # del vector de probabilidades de vecindad toma los 8 mayores\n",
    "        log = '\\tNearest to %s:' % valid_word\n",
    "        for k in range(top_k):\n",
    "          close_word = reverse_dictionary[nearest[k]]\n",
    "          log = '%s %s,' % (log, close_word)\n",
    "        print(log)\n",
    "        \n",
    "  #final_n = norm.eval() #tomar el denominador de normalizacion a ver si tiene ceros\n",
    "  final_skipgram_embeddings = normalized_embeddings.eval() \n",
    "    #me quedo con las features finales que definen cada concepto de palabra\n",
    "  print('End.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Vamos a dibujar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID for \"but\" is 42\n",
      "computing neighbors...\n",
      "\tNearest 8 to \"but\": however, and, although, while, though, when, since, did,\n",
      "projecting and plotting...\n",
      "\tPCA variance ratio [ 0.22748293  0.18809644]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAANmCAYAAABZuXIoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3XuQnlWB7/vfIgk9ORoQ50Tk4JAmeAmXXAgSIBCmYwrM\n4CgyIsp4oThR8IbUUFPFYKEm1liFM+5T4Gi8YDbjdpyIwsgct5ctCo1EJEYyIXhMMAemW3BAmwNE\nkBA6sM4fCU2DSSDpTjpZ/flUUfVeVj9rvanWqm+v53neUmsNAAAAe7d9RnoBAAAADJ24AwAAaIC4\nAwAAaIC4AwAAaIC4AwAAaIC4AwAAaMCwxF0pZX4pZW0p5VellIu38v6fl1IeLqWs3PLfpcMxLwAA\nAJuNHeoBSin7JPlsknlJ/ivJilLKv9da1z5n6I9rrW8a6nwAAAD8seHYuZuVZF2ttbfW2p/k60lO\n38q4MgxzAQAAsBXDEXcHJ7ln0PN7t7z2XCeUUlaVUr5TSjliGOYFAABgiyGflvkC3ZbkkFrrY6WU\nv0hyXZJX76a5AQAAmjcccfebJIcMev6KLa8NqLU+Oujx90opi0spL621Pvjcg5VS6jCsCQAAYK9V\na93hy9qGI+5WJHllKWVSkvuSvD3J2YMHlFIOrLX+dsvjWUnK1sLuabXqO57fwoULs3DhwpFeBnsJ\nvy+8UH5X2BF+X3ih/K6wI0rZuduVDDnuaq1PllI+lOQH2XwN35Ja65pSyvmb365fSnJmKeX9SfqT\nbEjytqHOCwAAwDOG5Zq7Wuv3k7zmOa99cdDjzyX53HDMBQAAwB8bli8xh5HQ1dU10ktgL+L3hRfK\n7wo7wu8LL5TfFXaHsqdd31ZKqXvamgAAAHaXUspO3VDFzh0AAEADxB0AAEADxB0AAEADxB0AAEAD\nxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0A\nAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEAD\nxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0A\nAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEAD\nxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0A\nAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEAD\nxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxB0A\nAEADxB0AAEADxB0AAEADxB0AAEADxB0AAEADxN0OOu+887J27dqRXgYAAMCzlFrrSK/hWUopdU9b\nEwAAwO5SSkmttezoz9m5247HHnssf/mXf5mjjz4606ZNyze+8Y3MnTs3K1euTJJMmDAhl156aWbM\nmJHZs2enr68vSfK73/0uf/VXf5UZM2bk6KOPzq233pok+drXvpbjjjsuM2fOzPvf//6IWAAAYLiI\nu+34/ve/n4MPPjj/8R//kdWrV2f+/PnPev8Pf/hDZs+enVWrVmXOnDm58sorkyQf/vCH09XVlVWr\nVmXlypU58sgjs3bt2lx99dW55ZZbsnLlyuyzzz752te+NhIfCwAAaJC4246pU6fm+uuvzyWXXJJl\ny5Zlv/32e9b7HR0dOe2005IkxxxzTHp6epIkN9xwQ97//vcn2bylOmHChPzoRz/KypUrc+yxx+bo\no4/ODTfckLvvvnu3fh4AAKBdY0d6AXuyV73qVVm5cmW++93v5qMf/Whe97rXpZRnTn0dN27cwOMx\nY8Zk06ZNSfKsMU+rteacc87JJz/5yV2/cAAAYNSxc7cd9913X8aPH5+//uu/zt/+7d8OXGv3tG1d\nMzdv3rwsXrw4SfLUU0/l97//febNm5drrrlm4Lq8hx56KL/+9a937QcAAABGjWGJu1LK/FLK2lLK\nr0opF29n3LGllP5Syl8Nx7y72h133JFZs2bl6KOPzic+8Yl89KMffdb7W9uhS5LLL788N954Y6ZN\nm5bXvva1WbNmTQ4//PD8/d//fU499dRMnz49p556au6///7d8TEAAIBRYMhfhVBK2SfJr5LMS/Jf\nSVYkeXutde1Wxl2fZEOS/15r/bdtHK/Zr0Lo6+tLT09POjs7M3HixJFeDgAAsAcaya9CmJVkXa21\nt9ban+TrSU7fyrgLklyT5HfDMOdeZ+nSqzNp0pSccsr7MmnSlCxdevVILwkAAGjIcMTdwUnuGfT8\n3i2vDSil/B9J3lxr/XySHS7QvV1fX18WLPhANmy4MevX35YNG27MggUfGLj+DgAAYKh21w1VLk8y\n+Fq8URV4PT092XffziTTtrwyLePGTRr46gQAAIChGo6vQvhNkkMGPX/FltcGe22Sr5fNdyD535P8\nRSmlv9b6f2/tgAsXLhx43NXVla6urmFY5sjp7OzME0/0JFmdzYG3Ov39vens7BzRdQEAACOvu7s7\n3d3dQz7OcNxQZUySO7P5hir3JflZkrNrrWu2Mf6qJN8ebTdUWbr06ixY8IGMGzcp/f29WbJkcc4+\n+20jvSwAAGAPs7M3VBly3G2ZfH6SK7L5NM8ltdbLSinnJ6m11i89Z+x/T/I/R1vcJe6WCQAAPL8R\njbvh1HLcAQAAPJ+R/CoEAAAARpi4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4\nAwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAA\naIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4\nAwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAA\naIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4\nAwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAA\naIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4AwAAaIC4\nAwAAaIC4AwAAaMDYkV4AAADsyRYtWpQXv/jFeeSRR3LyySfnda973bPev+mmm/LpT3863/72t0do\nhbCZuAMAgOdRSsnChQu3+z6MNKdlAgDAc3zyk5/Ma17zmpx88sm58847U2vNueeem3/7t39Lknz/\n+9/P4Ycfnte+9rUDr8FIE3cAADDIypUr841vfCOrV6/Od77znaxYsSKllIHduY0bN+a8887Ld77z\nnfz85z/P/fffP8Irhs3EHQAADHLzzTfnjDPOSEdHRyZMmJDTTz89tdaB99euXZvJkydn8uTJSZJ3\nvvOdI7VUeBZxBwAA2zE47Lb3Gow0cQcAAIOcfPLJue6667Jx48Y88sgj+fa3v51SykDQTZkyJb29\nvfnP//zPJMnSpUtHcrkwwN0yAQBgkKOPPjpve9vbMm3atBx44IGZNWtWkmfuiNnR0ZEvfvGLOe20\n0/KiF70oc+bMyaOPPjqSS4YkSdnTtpRLKXVPWxMAAAzW19eXnp6edHZ2ZuLEiSO9HBqzZad4h79f\nw2mZAACwA5YuvTqTJk3JKae8L5MmTcnSpVeP9JIgiZ07AAB4wfr6+jJp0pRs2HBjkmlJVmf8+Lnp\n7V1rB49hY+cOAAB2sZ6enuy7b2c2h12STMu4cZPS09MzcouCLcQdAAC8QJ2dnXniiZ4kq7e8sjr9\n/b3p7OwcuUXBFuIOAABeoIkTJ2bJksUZP35u9ttvZsaPn5slSxY7JZM9gmvuAABgB7lbJrvSzl5z\nJ+4AAAD2IG6oAgAAMIqJOwAAgAYMS9yVUuaXUtaWUn5VSrl4K++/qZRyeynlP0opPyulnDgc8wIA\nALDZkK+5K6Xsk+RXSeYl+a8kK5K8vda6dtCY/63W+tiWx1OTfKPWevg2jueaOwAAYNQayWvuZiVZ\nV2vtrbX2J/l6ktMHD3g67LZ4cZKnhmFeAAAAthiOuDs4yT2Dnt+75bVnKaW8uZSyJsm3k/yfwzAv\nAAAAW+y2G6rUWq/bcirmm5P8/e6aFwAAYDQYOwzH+E2SQwY9f8WW17aq1rqslDK5lPLSWuuDWxuz\ncOHCgcddXV3p6uoahmUCAADsebq7u9Pd3T3k4wzHDVXGJLkzm2+ocl+SnyU5u9a6ZtCYw2qtd215\nPDPJv9da/2wbx3NDFQAAYNTa2RuqDHnnrtb6ZCnlQ0l+kM2neS6pta4ppZy/+e36pSRvKaW8O8kT\nSTYkOWuo8wIAAPCMIe/cDTc7dwAAwGg2kl+FAAAAwAgTdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0Q\ndwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAA\nAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0Q\ndwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAA\nAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0Q\ndwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAA\nAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0Q\ndwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAA\nAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0Q\ndwAAAA0QdwAAAA0QdwAAAA0YlrgrpcwvpawtpfyqlHLxVt7/61LK7Vv+W1ZKmToc8wIAALBZqbUO\n7QCl7JPkV0nmJfmvJCuSvL3WunbQmOOTrKm1ri+lzE+ysNZ6/DaOV4e6JgAAgL1VKSW11rKjPzcc\nO3ezkqyrtfbWWvuTfD3J6YMH1FpvrbWu3/L01iQHD8O8AAAAbDEccXdwknsGPb8324+39yT53jDM\nCwAAwBZjd+dkpZS5Sc5NctLunBcAAKB1wxF3v0lyyKDnr9jy2rOUUqYl+VKS+bXWh7Z3wIULFw48\n7urqSldX1zAsEwAAYM/T3d2d7u7uIR9nOG6oMibJndl8Q5X7kvwsydm11jWDxhyS5EdJ3lVrvfV5\njueGKgAAwKi1szdUGfLOXa31yVLKh5L8IJuv4VtSa11TSjl/89v1S0k+muSlSRaXUkqS/lrrrKHO\nDQAAwGZD3rkbbnbuAACA0WwkvwoBAACAESbuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDu\nAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAA\nGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDu\nAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAA\nGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDu\nAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAA\nGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDu\nAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDuAAAAGiDugN2mt7c3U6dO\nfcHjb7rppvz0pz/dhSsCAGiHuAN2q1LKCx7b3d2dW265ZReuBgCgHeIO2K36+/vzzne+M0cccUTO\nOuusbNiwIYceemgefPDBJMltt92WuXPnpre3N1/4whdy+eWXZ+bMmfnJT34ywisHANizjR3pBQCj\ny5133pmrrroqxx9/fN7znvdk8eLFf7SbV0rJpEmT8r73vS8TJkzIRRddNEKrBQDYe9i5A3arQw45\nJMcff3yS5B3veEeWLVs2wisCAGiDuAN2q63t0o0dOzZPPfVUkuTxxx8fiWUBAOz1xB2wW/X29mb5\n8uVJkn/913/NnDlz0tnZmZ///OdJkmuvvXZg7IQJE/L73/9+RNYJALC3EXfAbjVlypR87nOfyxFH\nHJGHH34473//+/Oxj30sF154YWbNmpWxY5+5FPiNb3xjvvWtb7mhCgDAC1BqrSO9hmcppdQ9bU0A\nAAC7SykltdYX/v1RW9i5A/Y4fX19WbFiRfr6+kZ6KQAAew1xB+xRli69OpMmTckpp7wvkyZNydKl\nV4/0kgAA9gpOywT2GH19fZk0aUo2bLgxybQkqzN+/Nz09q7NxIkTR3p5AAC7hdMygb1eT09P9t23\nM5vDLkmmZdy4Senp6Rm5RQEA7CWGJe5KKfNLKWtLKb8qpVy8lfdfU0q5pZTyeCnlouGYE2hPZ2dn\nnniiJ8nqLa+sTn9/bzo7O0duUQAAe4khx10pZZ8kn03y+iRHJjm7lDLlOcP+vyQXJPnHoc4HtGvi\nxIlZsmRxxo+fm/32m5nx4+dmyZLFTskEAHgBhnzNXSnl+CQfr7X+xZbnf5ek1lo/tZWxH0/ySK31\n/9rO8VxzB6NcX19fenp60tnZKewAgFFnZ6+5G/v8Q57XwUnuGfT83iSzhuG4wCg1ceJEUQcAsIPc\nUAUAAKABw7Fz95skhwx6/ootr+20hQsXDjzu6upKV1fXUA4HAACwx+ru7k53d/eQjzMc19yNSXJn\nknlJ7kvysyRn11rXbGXsx5M8Wmv9b9s5nmvuAACAUWtnr7kbli8xL6XMT3JFNp/muaTWelkp5fxs\nvrHKl0opByb5eZIJSZ5K8miSI2qtj27lWOIOAAAYtUY07oaTuAMAAEaznY07N1QBAABogLgDAABo\ngLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgD\nAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABo\ngLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgD\nAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABo\ngLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgD\nAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABogLgDAABo\ngLiD55gwYcJILwEAAHaYuBvFent7M3Xq1JFexh6nlDLSSwAAgB0m7ka5PT1knnzyyZ36uTPOOCPH\nHntspk6dmi9/+ctJNu/IXXrppZkxY0Zmz56dvr6+JElPT09mz56d6dOn56Mf/eiwrR0AAHYncTfK\nbdq0Keedd16OOuqozJ8/Pxs3bsyqVatywgknZMaMGXnLW96S9evXp6+vL6997WuTJLfffnv22Wef\n3HvvvUmSV77ylXn88cfzwAMP5Mwzz8xxxx2X4447Lj/96U9Ta82hhx6a3//+9wNzvvrVr05fX99W\nxyfJokWL8u53vzsnnXRS3v3ud+/U57rqqquyYsWKrFixIldccUUefPDB/OEPf8js2bOzatWqzJkz\nJ1deeWWS5MILL8wHP/jB3H777TnooIOG8s8JAAAjRtyNcuvWrcsFF1yQX/ziF3nJS16Sa665Juec\nc07+8R//MatWrcpRRx2VRYsWZeLEidm4cWMeffTRLFu2LMcee2xuvvnm/PrXv86BBx6YP/mTP8mF\nF16Yiy66KMuXL88111yTBQsWpJSSN7/5zfnWt76VJPnZz36Wzs7OTJw4cavjn7ZmzZrccMMN+drX\nvrZTn+vyyy/PjBkzcvzxx+fee+/NunXr0tHRkdNOOy1Jcswxx6SnpydJ8pOf/CRvf/vbkyTvete7\nhvCvCQAAI2fsSC+AkTV58uSB6+5mzpyZu+66K+vXr89JJ52UJDnnnHNy1llnJUlmz56dZcuW5cc/\n/nE+8pGP5Hvf+16eeuqpzJkzJ0nywx/+MGvWrEmtNUny6KOP5rHHHstZZ52VT3ziEznnnHPy9a9/\nPW9729u2Oz5J3vSmN2Xffffdqc9000035YYbbsjy5cvT0dGRuXPn5vHHH8+4ceMGxowZMyabNm1K\nsvnU1KdPT316LQAAsLcRd6NcR0fHwOMxY8bk4Ycf3ubYOXPmDOzWnX766bnsssuyzz775A1veEOS\nzWG0fPnyZ0VUkpxwwgm566678sADD+S6667Lxz72se2OT5IXvehFO/2Z1q9fnwMOOCAdHR1Zu3Zt\nbr311oH5tubEE0/M0qVL8453vGOndwoBAGCkOS1zlHtu8Oy///454IAD8pOf/CRJ8tWvfjV//ud/\nnmRz3P3Lv/xLXvWqVyVJXvrSl+a73/3uwC7fqaeemiuuuGLgWLfffvvA4zPOOCMXXXRRjjjiiLzk\nJS953vFDMX/+/PT39+fII4/MRz7ykcyePTvJtm8ec/nll+dzn/tcpk+fnvvuu29Y1gAAALubnbtR\n7rnBU0rJV77ylZx//vnZsGFDJk+enKuuuipJMmnSpCQZiL2TTjopv/nNb7L//vsnSa644op88IMf\nzPTp0/Pkk0/m5JNPzuLFi5MkZ511VmbNmpWvfOUrA3Ntb/xQ7Lvvvvnud7/7R68PvqnLW97ylrzl\nLW9JknR2duaWW24ZeO8Tn/jEkNcAAAC7W9nTrjEqpdQ9bU20ra+vLz09PQM3egEAgJFUSkmtdYe/\ns8xpmewx+vr6smLFioHvn9sdli69OpMmTckpp7wvkyZNydKlV++2uQEAYDjZuWOPsHTp1Vmw4APZ\nd9/OPPFET5YsWZyzz37bLp2zr68vkyZNyYYNNyaZlmR1xo+fm97etXbwAAAYMXbu2Gv19fVlwYIP\nZMOGG7N+/W3ZsOHGLFjwgV2+g9fT05N99+3M5rBLkmkZN27SwPffAQDA3kTcMeJGKrI6OzfvEiar\nt7yyOv39vens7Nyl8wIAwK4g7hhxIxVZEydOzJIlizN+/Nzst9/MjB8/N0uWLHZKJgAAeyXX3LFH\nePqau3HjJqW/v3e3XHP3NHfLBABgT7Kz19yJO/YYIgsAAMQdAABAE9wtEwAAYBQTdwAAAA0QdwAA\nAA0QdwAAAA0QdwAAAA0QdwAAAA0QdwAAAA0YlrgrpcwvpawtpfyqlHLxNsZ8ppSyrpSyqpQyYzjm\nBQAAYLMhx10pZZ8kn03y+iRHJjm7lDLlOWP+IslhtdZXJTk/yReGOi8AAADPGI6du1lJ1tVae2ut\n/Um+nuT054w5Pcn/SJJa6/Ik+5dSDhyGuQEAAMjwxN3BSe4Z9PzeLa9tb8xvtjIGAACAneSGKgAA\nAA0YOwzH+E2SQwY9f8WW15475s+eZ8yAhQsXDjzu6upKV1fXUNcIAACwR+ru7k53d/eQj1NqrUM7\nQCljktyZZF6S+5L8LMnZtdY1g8acluSDtdY3lFKOT3J5rfX4bRyvDnVNAAAAe6tSSmqtZUd/bsg7\nd7XWJ0spH0ryg2w+zXNJrXVNKeX8zW/XL9Vav1tKOa2U8v8m+UOSc4c6LwAAAM8Y8s7dcLNzBwAA\njGY7u3PnhioAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcA\nAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAAN\nEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcA\nAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAAN\nEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcA\nAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAANEHcAAAAN\nEHcwyh166KF58MEHs379+nz+858feP2mm27KG9/4xl06d29vb6ZOnbpL5wAAGC3EHYxypZQkyUMP\nPZTFixdv9b3dMT8AAEMj7mAUOeOMM3Lsscdm6tSp+fKXv/ys9y655JLcfffdmTlzZi6++OIkySOP\nPJK3vvWtOfzww/Oud71rYOyPfvSjzJw5M9OnT8973vOe9Pf3J3lmFzBJbrvttsydOzdJ8sADD+TU\nU0/N1KlT8973vjednZ0D4zZt2pTzzjsvRx11VObPn5+NGzfu8n8HAIAWiTsYRa666qqsWLEiK1as\nyBVXXJHTMhcFAAAbmElEQVQHH3wwtdYkyWWXXZbDDjssK1euzKc+9akkyapVq/KZz3wmv/zlL3PX\nXXfllltuycaNG3Puuefmm9/8Zm6//fb09/cPnM753F24p58vWrQo8+bNyx133JEzzzwz99xzz8CY\ndevW5YILLsgvfvGL7L///rn22mt3xz8FAEBzxB2MIpdffnlmzJiR448/Pvfee2/WrVu33dMiZ82a\nlYMOOiillMyYMSM9PT258847M3ny5Bx22GFJknPOOSc//vGPk2QgFJ9r2bJlefvb354kef3rX58D\nDjhg4L3JkycPXHd3zDHHpKenZzg+KgDAqDN2pBcA7B433XRTbrjhhixfvjwdHR2ZO3duHn/88e3+\nTEdHx8DjMWPGZNOmTUm2HXFjx47NU089lSTbPfbgn3/uHM+3JgAAts7OHYwS69evzwEHHJCOjo6s\nXbs2t956a5JnQmvChAl55JFHnvc4r3nNa9Lb25u77747SfLVr341XV1dSTZfc3fbbbclybNOrzzx\nxBNz9dVXJ0l+8IMf5OGHHx54b1uhCADAjhF3MErMnz8//f39OfLII/ORj3wks2fPTvLMdXEvfelL\nc+KJJ2batGkDN1QZ7OlxHR0dueqqq3LmmWdm+vTpGTNmTM4///wkycc+9rF8+MMfzqxZszJ27DMn\nBnz84x/P9ddfn2nTpuXaa6/Ny1/+8kyYMOFZxwUAYGjKnvZX81JK3dPWBAzNE088kTFjxmTMmDG5\n9dZb84EPfCArV65MkvT19aWnpyednZ2ZOHHiCK8UAGDklVJSa93hv4C75g7Y5X7961/nrLPOylNP\nPZWOjo5ceeWVSZKlS6/OggUfyL77duaJJ3qyZMninH3220Z4tQAAeyc7d8CI6Ovry6RJU7Jhw41J\npiVZnfHj56a3d60dPABgVNvZnTvX3AEjoqenJ/vu25nNYZck0zJu3CRfhQAAsJPEHTAiOjs3n4qZ\nrN7yyur09/ems7Nz5BYFALAXE3fAiJg4cWKWLFmc8ePnZr/9Zmb8+LlZsmSxUzIBAHaSa+6AEeVu\nmQAAz7az19yJOwAAgD2IG6oAAACMYuIOAACgAeIOAACgAeIOAACgAeIOAACgAeIOAACgAeIOAACg\nAeIOAACgAeIOAACgAeIOAACgAeIOAACgAeIOAACgAUOKu1LKAaWUH5RS7iyl/K9Syv7bGLeklPLb\nUsrqocwHAADA1g115+7vkvyw1vqaJDckuWQb465K8vohzgUAAMA2DDXuTk/ylS2Pv5LkzVsbVGtd\nluShIc4FAADANgw17l5Wa/1tktRa70/ysqEvCQAAgB019vkGlFKuT3Lg4JeS1CSXbmV4HaZ1AQAA\nsAOeN+5qrads670tN0k5sNb621LKy5P8bjgWtXDhwoHHXV1d6erqGo7DAgAA7HG6u7vT3d095OOU\nWnd+s62U8qkkD9ZaP1VKuTjJAbXWv9vG2M4k3661Tn2eY9ahrAkAAGBvVkpJrbXs6M8N9Zq7TyU5\npZRyZ5J5SS7bspiDSin/c9Di/jXJLUleXUr5dSnl3CHOCwAAwCBD2rnbFezcAQAAo9lI7dwBAACw\nBxB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3\nAAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAA\nDRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3\nAAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAA\nDRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3\nAAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAA\nDRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3\nAAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAA\nDRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRB3AAAADRhS3JVSDiil/KCUcmcp\n5X+VUvbfyphXlFJuKKX8P6WUO0opHx7KnAAAAPyxoe7c/V2SH9ZaX5PkhiSXbGXMpiQX1VqPTHJC\nkg+WUqYMcV4AAAAGGWrcnZ7kK1sefyXJm587oNZ6f6111ZbHjyZZk+TgIc4LAADAIEONu5fVWn+b\nbI64JC/b3uBSSmeSGUmWD3FeAAAABhn7fANKKdcnOXDwS0lqkku3Mrxu5zgvTnJNkgu37OABAAAw\nTJ437mqtp2zrvVLKb0spB9Zaf1tKeXmS321j3NhsDruv1lr//fnmXLhw4cDjrq6udHV1Pd+PAAAA\n7JW6u7vT3d095OOUWre52fb8P1zKp5I8WGv9VCnl4iQH1Fr/bivj/keSB2qtF72AY9ahrAkAAGBv\nVkpJrbXs8M8NMe5emuQbSf4sSW+Ss2qtD5dSDkpyZa31L0spJyb5cZI7svm0zZrkI7XW72/jmOIO\nAAAYtUYk7nYFcQcAAIxmOxt3Q71bJgAAAHsAcQcAANAAcQcAANAAcQcAANAAcQcAANAAcQcAANAA\ncQcAANAAcQcAANAAcQcAANAAcQcAANAAcQcAANAAcQcAANAAcQcAANAAcQcAANAAcQcAANAAcQcA\nANAAcQcAANAAcQcAANAAcQcAANAAcQcAANAAcQcAANAAcQcAANAAcQcAANAAcQcAANAAcQcAANAA\ncQcAANAAcQcAANAAcQcAANAAcQcAANAAcQcAANAAcQfschMmTBjpJQAANE/cAbtcKWWklwDbtX79\n+nz+859Pktx000154xvfuEvn6+3tzdSpU3fpHACMPuIOGLJPf/rT+exnP5sk+Zu/+ZvMmzcvSXLj\njTfmne98Z5Lk0ksvzYwZMzJ79uz09fUlSR544IGceeaZOe6443Lcccflpz/9aZJk0aJFWbBgQebO\nnZtXvvKV+ad/+qcR+FSMJg899FAWL16cJKm17pY/SPijBwDDTdwBQzZnzpzcfPPNSZLbbrstf/jD\nH/Lkk0/m5ptvzsknn5xHH300s2fPzqpVqzJnzpxceeWVSZILL7wwF110UZYvX55rrrkmCxYsGDjm\nnXfemeuvvz7Lly/PokWL8uSTT47IZ2N0uOSSS3L33Xdn5syZufjii/PII4/krW99aw4//PC8613v\nGhj3ox/9KDNnzsz06dPznve8J/39/UmSQw89NA8++GCSzf8bmDt3bpLNf8A49dRTM3Xq1Lz3ve9N\nZ2fnwLhNmzblvPPOy1FHHZX58+dn48aNu/lTA9AacQcM2THHHJPbbrstjzzySDo6OnLCCSdkxYoV\nufnmmzNnzpx0dHTktNNOGxjb09OTJPnhD3+YD33oQzn66KPzpje9KY8++mgee+yxJMkb3vCGjB07\nNn/6p3+aAw88ML/97W9H6uMxClx22WU57LDDsnLlyvzDP/xDVq1alc985jP55S9/mbvuuiu33HJL\nNm7cmHPPPTff/OY3c/vtt6e/v3/gVM7n7sI9/XzRokWZN29e7rjjjpx55pm55557BsasW7cuF1xw\nQX7xi19k//33z7XXXrv7PjAATRo70gsA9n5jx45NZ2dn/vmf/zknnnhipk2blhtvvDF33XVXDj/8\n8Iwd+8z/1YwZMyabNm1Ksvn0t+XLl2fcuHF/dMyOjo6Bx/vss8/Az8DuMGvWrBx00EFJkhkzZqSn\npycvfvGLM3ny5Bx22GFJknPOOSeLFy/Ohz/84dRat3qcZcuW5brrrkuSvP71r88BBxww8N7kyZMH\nrrsb/EcPANhZdu6AYTFnzpx8+tOfzsknn5yTTjopX/jCFzJz5szt/sypp56aK664YuD57bffvquX\nCS/I4D8uPPcPElszduzYPPXUU0mSxx9/fJvHHfzz25oDAHaWuAOGxZw5c3L//ffnhBNOyMte9rKM\nHz8+c+bMSbLtG0dcccUV+fnPf57p06fnqKOOyhe/+MX/v737j7WzvusA/v6sLc1VgcBWytiPXjdd\nYWNdAZlCKbZgs4HLtshEh2yu1qSGics0CiM4tmTqSHAqQWTDOhgkwALEETPlR2hjXehSC6wwBm7g\n7dwM3Z2Tn3bSwtc/7qWWtrf3tre95/S5r1dy03PP+Z7n+dz0k+ec9/N9fux2nAtPcKAdeuihefbZ\nZ5OMHeDmz5+fTZs25YknnkiS3HDDDVmyZEmSkXPuNmzYkCSvOLxy0aJFueWWW5Ikd911V5566qnt\nr421HgDYVw7LBPaLM8444xUXhHj00Ue3P37mmWe2Pz7nnHNyzjnnJEle/epX5+abb95lWZdddtkr\nft+4ceP+Lhde4cgjj9x+SPHAwEDmzp27/bWXdy7Mnj07X/ziF/OBD3wgL774Yk4++eSsXLkySfLJ\nT34yK1asyOGHH7498CUjvXzeeeflxhtvzCmnnJKjjz56e5C00wKA/a36bc9hVbV+qwmYWsPDwxka\nGsrg4GDmzJnT63Jgn73wwguZMWNGZsyYkXXr1uWCCy7I/fff3+uyAOhzVZXW2l7vBTRzB/SVm266\nJStWXJBDDhnMCy8MZdWqq/PBD/5ar8uCffLd73435557bl566aXMnj17+21AEjsxANj/zNwBfWN4\neDjz5h2bLVtWJ1mQZGMGBpZm06ZHffmlU+zEAGBP9nXmzgVVgL4xNDSUQw4ZzEiwS5IFmTVrnkvE\n0ynDw8NZseKCbNmyOk8/vSFbtqzOihUXZHh4uNelAXCQE+6AvjE4ODKLkbx8AZWN2bp1UwYHB3tX\nFOxndmIAcKAId0DfmDNnTlatujoDA0tz2GEnZmBgaVatutohmXSKnRgAHCjOuQP6jgtN0HUvn3M3\na9a8bN26yTl3ALzCvp5zJ9wBQA/YiQHAWIQ7AACADnC1TAAAgGlMuAMAAOgA4Q4AAKADhDsAAIAO\nEO4AAAA6QLgDAADoAOEOAACgA4Q7AACADhDuAAAAOkC4AwAA6ADhDgAAoAOEO2DKHXroobt9/vOf\n/3xuvPHGJMny5ctz++23T2VZAAAHtZm9LgCYfqpqt8+vXLlyiisBAOgOM3fAfnfFFVfkqquuSpJ8\n/OMfz5lnnpkkWb16dc4///wkyaWXXpqFCxfm1FNPzfDwcJLk05/+dD73uc/tsrz7778/S5Ysyckn\nn5yzzjormzdvnqK/BADg4CHcAfvd4sWLs3bt2iTJhg0b8vzzz+fFF1/M2rVrc/rpp+e5557Lqaee\nmgcffDCLFy/OtddeO+aytm3blgsvvDC33XZb1q9fn+XLl+eSSy6Zqj8FAOCg4bBMYL876aSTsmHD\nhjz77LOZPXt2TjrppKxfvz5r167NlVdemdmzZ+fss8/ePvaee+4Zc1mPPfZYHn744Sxbtiyttbz0\n0ks55phjpupPAQA4aAh3wH43c+bMDA4O5rrrrsuiRYuyYMGCrF69Oo8//niOO+64zJz5/5ueGTNm\nZNu2bWMuq7WW448/Pl/72temonQAgIOWwzKBA2Lx4sW54oorcvrpp+e0007LNddckxNPPHGvlzN/\n/vwMDw9n3bp1SUYO03zkkUf2d7kAAAc94Q44IBYvXpwnn3wyp5xySo466qgMDAxk8eLFSca+WuaO\nXh4za9as3HrrrbnooouycOHCnHDCCbnvvvsOaO0AAAejaq31uoZXqKrWbzUBvTU8PJyhoaEMDg5m\nzpw5vS4HAOCAqqq01sbfG74TM3dAX7vpplsyb96xWbbsdzJv3rG56aZbel0SAEBfMnMH9K3h4eHM\nm3dstmxZnWRBko0ZGFiaTZseNYMHAHSWmTugc4aGhnLIIYMZCXZJsiCzZs3L0NBQ74oCAOhTwh3Q\ntwYHB/PCC0NJNo4+szFbt27K4OBg74oCAOhTwh3Qt+bMmZNVq67OwMDSHHbYiRkYWJpVq652SCYA\nwG445w7oe66WCQBMJ/t6zp1wBwAA0EdcUAUAAGAaE+4AAAA6QLgDAADoAOEOAACgA4Q7AACADhDu\nAAAAOkC4AwAA6ADhDgAAoAOEOwAAgA6YVLirqiOq6q6qeqyq7qyqw3czZnZVfb2qHqiqh6rqssms\nEwAAgF1Ndubu4iT3tNbmJ7k3ySd2HtBa+98kS1trJyRZmOSsqnrnJNcLAADADiYb7t6X5PrRx9cn\nef/uBrXW/mf04ewkM5O0Sa4XAACAHUw23B3VWtucJK21J5MctbtBVfWqqnogyZNJ7m6trZ/kegEA\nANjBzPEGVNXdSebu+FRGZt4u3c3w3c7ItdZeSnJCVR2W5O+r6q2ttUf2oV4AAAB2Y9xw11pbNtZr\nVbW5qua21jZX1dFJfjDOsp6pqtVJ3p1kzHD3qU99avvjJUuWZMmSJeOVCQAAcFBas2ZN1qxZM+nl\nVGv7fvpbVV2e5Eettcur6qIkR7TWLt5pzGuSbG2tPV1VA0nuTPLZ1tpXx1hmm0xNAAAAB7OqSmut\n9vp9kwx3Ryb5cpI3JNmU5NzW2lNV9dok17bW3lNVb8/IxVZeNfpzS2vtT/awTOEOAACYtnoS7g4E\n4Q4AAJjO9jXcTfZqmQAAAPQB4Q4AAKADhDsAAIAOEO4AAAA6QLgDAADoAOEOAACgA4Q7AACADhDu\nAAAAOkC4AwAA6ADhDgAAoAOEOwAAgA4Q7gAAADpAuAMAAOgA4Q4AAKADhDsAAIAOEO4AAAA6QLgD\nAADoAOEOAACgA4Q7AACADhDuAAAAOkC4AwAA6ADhDgAAoAOEOwAAgA4Q7gAAADpAuAMAAOgA4Q4A\nAKADhDsAAIAOEO4AAAA6QLgDAADoAOEOAACgA4Q7AACADhDuAAAAOkC4AwAA6ADhDgAAoAOEOwAA\ngA4Q7gAAADpAuAMAAOgA4Q4AAKADhDsAAIAOEO4AAAA6QLgDAADoAOEOAACgA4Q7AACADhDuAAAA\nOkC4AwAA6ADhDgAAoAOEOwAAgA4Q7gAAADpAuAMAAOgA4Q4AAKADhDsAAIAOEO4AAAA6QLgDAADo\nAOEOAACgA4Q7AACADhDuAAAAOkC4AwAA6ADhDgAAoAOEOwAAgA4Q7gAAADpAuAMAAOgA4Q4AAKAD\nhDsAAIAOEO4AAAA6QLgDAADoAOEOAACgA4Q7AACADhDuAAAAOkC4AwAA6ADhDgAAoAOEOwAAgA4Q\n7gAAADpAuAMAAOgA4Q4AAKADhDsAAIAOEO4AAAA6QLgDAADoAOEOAACgA4Q7AACADhDuAAAAOkC4\nAwAA6ADhDgAAoAOEOwAAgA4Q7gAAADpgUuGuqo6oqruq6rGqurOqDt/D2FdV1f1Vdcdk1gkAAMCu\nJjtzd3GSe1pr85Pcm+QTexj7sSSPTHJ9sN2aNWt6XQIHEf3CROkV9oZ+YaL0ClNhsuHufUmuH318\nfZL3725QVb0+ydlJ/naS64PtbCTZG/qFidIr7A39wkTpFabCZMPdUa21zUnSWnsyyVFjjPuLJH+Y\npE1yfQAAAOzGzPEGVNXdSebu+FRGQtqluxm+S3irql9Osrm19mBVLRl9PwAAAPtRtbbvk2lV9a0k\nS1prm6vq6CSrW2vH7TTmT5Ocn2RbkoEkhya5vbX24TGWaXYPAACY1lprez0pNtlwd3mSH7XWLq+q\ni5Ic0Vq7eA/jfzHJH7TW3rvPKwUAAGAXkz3n7vIky6rqsSRnJvlsklTVa6vqHyZbHAAAABMzqZk7\nAAAA+sNkZ+4mxU3Q2RsT6Zeqen1V3VtV36yqh6rq93pRK71RVe+uqker6t9GDxXf3Zgrq+rbVfVg\nVS2c6hrpH+P1S1WdV1XfGP35l6p6ey/qpPcmsm0ZHXdyVW2tql+ZyvroLxP8LFpSVQ9U1cNVtXqq\na6Q/TOBz6LCqumP0O8tDVfWR8ZbZ03AXN0Fn70ykX7Yl+f3W2tuSnJLko1V17BTWSI9U1auSXJXk\nXUneluSDO//fV9VZSd7cWvvZJCuTXDPlhdIXJtIvSZ5Icnpr7R1JPpPk2qmtkn4wwV55edxnk9w5\ntRXSTyb4WXR4kr9O8p7W2vFJfnXKC6XnJrht+WiSb7bWFiZZmuTPq2qPdzvodbhzE3T2xrj90lp7\nsrX24Ojj55J8K8nrpqxCeumdSb7dWtvUWtua5OaM9MyO3pfkS0nSWvt6ksOram6Yjsbtl9bautba\n06O/rottyXQ1kW1LklyY5NYkP5jK4ug7E+mX85Lc1lr7fpK01n44xTXSHybSKy0jdxrI6L//1Vrb\ntqeF9jrcuQk6e2Oi/ZIkqarBJAuTfP2AV0Y/eF2S/9jh9+9l1y/jO4/5/m7GMD1MpF929NtJ/vGA\nVkS/GrdXquqYJO9vrf1N3M93upvItuUtSY6sqtVVtb6qPjRl1dFPJtIrVyV5a1X9Z5JvZORIxj0a\n9ybmk+Um6OyNyfbLDsv5qYzsQf3Y6AwewD6pqqVJlic5rde10Lf+MsmO58v4rsKezExyYpIzkvxk\nkvuq6r7W2nd6WxZ96F1JHmitnVFVb05yd1Ut2NN32wMe7lpry8Z6rao2V9XcHW6CvrtDGRYleW9V\nnZ3Rm6BX1ZfGugk6B7f90C8ZPRb51iQ3tNa+coBKpf98P8kbd/j99aPP7TzmDeOMYXqYSL+kqhYk\n+UKSd7fW/nuKaqO/TKRXfi7JzVVVSV6T5Kyq2tpacxG46Wci/fK9JD9srf04yY+r6p+TvCOJcDe9\nTKRXlif5syRprT1eVf+e5Ngk/zrWQnt9WOYdST4y+vg3k+zyRby1dklr7Y2ttTcl+fUk9wp209a4\n/TLq75I80lr7q6koir6xPsnPVNW8qjokI9uLnb9Y3ZHkw0lSVb+Q5KmXD/Vl2hm3X6rqjUluS/Kh\n1trjPaiR/jBur7TW3jT689MZ2bl4gWA3bU3ks+grSU6rqhlV9RNJfj4j1whgeplIr2xK8ktJMnqN\ngLdk5GJfYzrgM3fjuDzJl6vqtzJS/LnJyE3Qk1zbWntPL4uj74zbL1W1KMlvJHmoqh7IyKGbl7TW\n/qlXRTM1WmsvVtXvJrkrIzuuVrXWvlVVK0debl9orX21qs6uqu8keT4je8SYhibSL0n+OMmRSa4e\nnZHZ2lp7Z++qphcm2CuveMuUF0nfmOBn0aNVdWeSjUleTPKF1porwk8zE9y2fCbJdVW1cfRtf9Ra\n+9Gelusm5gAAAB3Q68MyAQAA2A+EOwAAgA4Q7gAAADpAuAMAAOgA4Q4AAKADhDsAAIAOEO4AAAA6\nQLgDAADogP8DN2JHg724MPkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f9d7d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SKIPGRAM\n",
    "show_nearest_embeddings_PCA('but',final_skipgram_embeddings,area=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID for \"woman\" is 1014\n",
      "computing neighbors...\n",
      "\tNearest 8 to \"woman\": man, person, character, men, dolphin, score, stapleton, people,\n",
      "projecting and plotting...\n",
      "\tPCA variance ratio [ 0.20863956  0.17336025]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAANmCAYAAABZuXIoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCHcAAAANINwBAAA0gHAHAADQAP8PoLCzz7ujuPgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fe43810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SKIPGRAM\n",
    "show_nearest_embeddings_PCA('woman',final_skipgram_embeddings,area=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QB5EFrBnpNnc"
   },
   "source": [
    "---\n",
    "\n",
    "CBOW\n",
    "-------\n",
    "\n",
    "An alternative to skip-gram is another Word2Vec model called [CBOW](http://arxiv.org/abs/1301.3781) (Continuous Bag of Words). In the CBOW model, instead of predicting a context word from a word vector, you predict a word from the sum of all the word vectors in its context. Implement and evaluate a CBOW model trained on the text8 dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### NOTA: me apoyo en su generate_batch de base pero quizás debería hacerme el mío que en lugar de poner como objetivo la palabra de en medio ponga la del final de cada ventana (aunque en su artículo dicen que quieren buscar el de enmedio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against', 'early', 'working', 'class', 'radicals', 'including', 'the']\n",
      "\n",
      "with num_skips = 2 and skip_window = 1:\n",
      "    IDs:\n",
      "['anarchism', 'as']\n",
      "['originated', 'a']\n",
      "['term', 'as']\n",
      "['of', 'a']\n",
      "['term', 'abuse']\n",
      "['first', 'of']\n",
      "['used', 'abuse']\n",
      "['against', 'first']\n",
      "    IDlabels: ['originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used']\n",
      "\n",
      "with num_skips = 4 and skip_window = 2:\n",
      "    IDs:\n",
      "['originated', 'anarchism', 'term', 'a']\n",
      "['originated', 'as', 'of', 'term']\n",
      "['of', 'a', 'as', 'abuse']\n",
      "['first', 'abuse', 'term', 'a']\n",
      "['first', 'term', 'used', 'of']\n",
      "['against', 'used', 'of', 'abuse']\n",
      "['early', 'first', 'against', 'abuse']\n",
      "['used', 'working', 'early', 'first']\n",
      "    IDlabels: ['as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against']\n"
     ]
    }
   ],
   "source": [
    "data_index = 0\n",
    "\n",
    "#batch_size, tamaño del lote a meter en la red neural para aprender\n",
    "#skip_window, tamaño del lado derecho e izquierdo de la ventana alrededor de una palabra (es simétrica)\n",
    "#num_skips, distancia de palabra adyacente que va a tomar como etiqueta  (2 x skip_window)\n",
    "\n",
    "def generate_batch_cbow(batch_size, num_skips, skip_window):\n",
    "    ids, lids = generate_batch_skipgram(num_skips*batch_size, num_skips, skip_window)\n",
    "    batch = lids.reshape(batch_size,num_skips)\n",
    "    labels = ids[np.arange(0,num_skips*batch_size,num_skips)].reshape(batch_size,1)\n",
    "\n",
    "    return batch, labels\n",
    "    \n",
    "#Ejecucion de ejemplo para las primeras ocho palabras del diccionario (un lote de ocho)\n",
    "\n",
    "lote = 8\n",
    "print('data:', [reverse_dictionary[di] for di in data[:2*lote]])\n",
    "\n",
    "for num_skips, skip_window in [(2, 1), (4, 2)]:\n",
    "    print('\\nwith num_skips = %d and skip_window = %d:' % (num_skips, skip_window))\n",
    "\n",
    "    data_index = 0\n",
    "    batch, labels = generate_batch_cbow(batch_size=lote, num_skips=num_skips, skip_window=skip_window)\n",
    "    \n",
    "    def show2D(a):\n",
    "        for L in a:\n",
    "            print([reverse_dictionary[i] for i in L])\n",
    "    \n",
    "    print('    IDs:')\n",
    "    show2D(batch)\n",
    "    print('    IDlabels:', [reverse_dictionary[li] for li in labels.reshape(lote)])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "8pQKsV4Vwlzy"
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# DECLARACION CBOW\n",
    "##################\n",
    "\n",
    "batch_size = 128 #Lotes de entrenamiento.\n",
    "\n",
    "embedding_size = 128 # Dimension of the embedding vector. Las features de cada palabra que la distinguen.\n",
    "skip_window = 1 # How many words to consider left and right. Semiventana, al final ventana de 3.\n",
    "                # Es poco debería ser mayor pero más procesamiento también.\n",
    "num_skips = 2 # How many times to reuse an input to generate a label. \n",
    "                #Normalmente ancho-ventana - 1 (3-1 = 2). O 2*skip_window\n",
    "\n",
    "# We pick a random validation set to sample nearest neighbors. here we limit the\n",
    "# validation samples to the words that have a low numeric ID, which by construction are also the most frequent. \n",
    "# Va a utilizar como validationSet las palabras más comunes del diccionario (las del principio)\n",
    "valid_size = 16 # Random set of words to evaluate similarity on. Escoge 16 para validacion.\n",
    "valid_window = 100 # Only pick dev samples in the head of the distribution. Las escoge de entre las 100 primeras.\n",
    "valid_examples = np.array(random.sample(range(valid_window), valid_size))\n",
    "\n",
    "num_sampled = 64 # Number of negative examples to sample. Muestras aleatorias de entre el lote que sirven para calcular LOSS.\n",
    "\n",
    "learning_rate = 1.0\n",
    "\n",
    "graphCB_NCE = tf.Graph()\n",
    "\n",
    "with graphCB_NCE.as_default(), tf.device('/cpu:0'):\n",
    "\n",
    "  # Input data.\n",
    "  train_dataset = tf.placeholder(tf.int32, shape=[batch_size, num_skips])\n",
    "  train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "  valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "  \n",
    "  # Variables y su inicializacion.\n",
    "      #RELACION CON OTROS CONCEPTOS (primer layer):\n",
    "  softmax_weights = tf.Variable(tf.truncated_normal([vocabulary_size, embedding_size],stddev=1.0 / math.sqrt(embedding_size)))\n",
    "  softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "       #CONCEPTO-FEATURES DE UNA PALABRA (segundo layer):\n",
    "  embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0)) \n",
    "    \n",
    "  # Model.\n",
    "  # Look up embeddings for outputs.\n",
    "  embed = tf.zeros([batch_size, embedding_size])\n",
    "  for j in range(num_skips): #El embedding objetivo es la suma de los embeddings de la bolsa de palabras correspondiente\n",
    "        embed += tf.nn.embedding_lookup(embeddings, train_dataset[:, j])\n",
    "\n",
    "  # Compute the softmax loss, using a sample of the negative train data each time.\n",
    "  loss = tf.reduce_mean(\n",
    "           tf.nn.nce_loss(softmax_weights, softmax_biases, embed, train_labels, num_sampled, vocabulary_size))\n",
    "      \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.AdagradOptimizer(learning_rate).minimize(loss)\n",
    "  \n",
    "  # Compute the similarity between minibatch examples and all embeddings.\n",
    "  # We use the cosine distance:\n",
    "  norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "  normalized_embeddings = embeddings / norm\n",
    "  valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n",
    "  similarity = tf.matmul(valid_embeddings, tf.transpose(normalized_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "step 0\t0s\tAverage loss: 285.754028\n",
      "\tNearest to no: gibraltarians, prom, nara, upstate, campuses, petition, paused, marginal,\n",
      "\tNearest to so: boards, military, cummings, regolith, aquarium, receiving, hingis, haldane,\n",
      "\tNearest to the: rosicrucians, layouts, naka, beti, silly, fandango, acutely, departed,\n",
      "\tNearest to in: nontraditional, cling, timecode, beckett, hyde, milton, astatine, linebarger,\n",
      "\tNearest to into: rationing, importantly, steep, bronzes, cartographic, psychedelic, selma, como,\n",
      "\tNearest to their: lambert, superficial, parametric, hitchens, blackadder, hasidim, leper, thackeray,\n",
      "\tNearest to only: steffens, sanity, metastability, afoul, differences, lucius, replied, taunted,\n",
      "\tNearest to its: appearance, transference, deterred, saxophonist, oshii, phase, aim, syncopation,\n",
      "\tNearest to three: roster, elisabetta, linnaeus, bruges, greenstone, lawless, cerrado, remit,\n",
      "\tNearest to had: academic, ambassador, computability, maitreya, missile, cord, casale, puberty,\n",
      "\tNearest to united: xserve, compliance, portable, financed, yosef, berliner, tease, formalisms,\n",
      "\tNearest to his: hustler, et, deconstruction, endothermic, darling, poachers, elsinore, icrc,\n",
      "\tNearest to often: hesitation, choreographer, serpento, trondheim, flawless, drinks, crossovers, analogy,\n",
      "\tNearest to five: softer, belonged, tenet, filing, operating, tnf, overthrow, indochina,\n",
      "\tNearest to up: jeffery, bears, martyrs, invasions, criteria, bugs, bash, aspire,\n",
      "\tNearest to most: rendering, hemiparesis, silent, meter, looters, freeware, dysentery, linebackers,\n",
      "step 2000\t11s\tAverage loss: 121.202426\n",
      "step 4000\t22s\tAverage loss: 52.453746\n",
      "step 6000\t33s\tAverage loss: 32.362335\n",
      "step 8000\t43s\tAverage loss: 21.843881\n",
      "step 10000\t53s\tAverage loss: 15.466744\n",
      "\tNearest to no: earthworm, a, another, prom, preferential, azimuth, chimneys, semicircular,\n",
      "\tNearest to so: ligament, jeremiah, tyne, cytokines, cours, radiating, threads, cloister,\n",
      "\tNearest to the: their, its, a, his, macrophages, this, determinant, each,\n",
      "\tNearest to in: and, between, at, on, of, from, during, with,\n",
      "\tNearest to into: from, since, neutralize, when, by, reconciling, postponed, via,\n",
      "\tNearest to their: his, its, the, her, tl, swivel, reductionist, swordsman,\n",
      "\tNearest to only: measles, imran, andrey, bckgr, lusignan, abbots, macs, acapulco,\n",
      "\tNearest to its: their, his, shapiro, the, each, likeness, her, cid,\n",
      "\tNearest to three: five, four, zero, nine, six, two, eight, seven,\n",
      "\tNearest to had: has, was, were, have, are, will, forbids, etiquette,\n",
      "\tNearest to united: curries, divers, zum, demonstrating, derive, lowering, quickdraw, trypanosomiasis,\n",
      "\tNearest to his: their, its, her, the, smyrna, s, cid, each,\n",
      "\tNearest to often: still, being, choreographer, also, not, generally, assassins, duly,\n",
      "\tNearest to five: nine, six, zero, three, four, seven, eight, two,\n",
      "\tNearest to up: hacking, overheating, grounding, resemble, foul, tm, points, overlay,\n",
      "\tNearest to most: more, critics, counterproductive, classical, interestingly, booth, stretches, masurian,\n",
      "step 12000\t64s\tAverage loss: 12.602464\n",
      "step 14000\t75s\tAverage loss: 10.179381\n",
      "step 16000\t85s\tAverage loss: 8.826843\n",
      "step 18000\t96s\tAverage loss: 7.690220\n",
      "step 20000\t107s\tAverage loss: 6.664198\n",
      "\tNearest to no: a, juicy, another, earthworm, any, equipment, provoked, petition,\n",
      "\tNearest to so: gildas, frs, entre, straps, thea, lightest, stand, cowdery,\n",
      "\tNearest to the: its, their, his, this, a, each, some, our,\n",
      "\tNearest to in: at, on, and, during, between, within, of, although,\n",
      "\tNearest to into: from, between, for, via, after, within, with, to,\n",
      "\tNearest to their: his, its, the, her, any, reaffirmed, many, a,\n",
      "\tNearest to only: nephews, still, teamsters, bombers, erectile, unitas, lodger, oct,\n",
      "\tNearest to its: their, his, the, her, each, alabaster, shapiro, our,\n",
      "\tNearest to three: four, six, five, eight, seven, two, nine, zero,\n",
      "\tNearest to had: has, have, was, were, having, skeleton, never, unidentified,\n",
      "\tNearest to united: galician, derive, zum, guderian, tease, boutique, mitanni, pore,\n",
      "\tNearest to his: their, its, her, the, my, s, each, your,\n",
      "\tNearest to often: usually, generally, still, sometimes, being, not, commonly, also,\n",
      "\tNearest to five: four, six, three, eight, seven, nine, two, zero,\n",
      "\tNearest to up: out, them, subject, back, resemble, curfew, hacking, overheating,\n",
      "\tNearest to most: more, counterproductive, wipe, critics, catapults, coppola, looted, dtp,\n",
      "step 22000\t117s\tAverage loss: 6.438354\n",
      "step 24000\t128s\tAverage loss: 6.038579\n",
      "step 26000\t138s\tAverage loss: 5.559343\n",
      "step 28000\t149s\tAverage loss: 5.481087\n",
      "step 30000\t160s\tAverage loss: 5.256147\n",
      "\tNearest to no: another, a, any, little, azimuth, officiate, satr, gone,\n",
      "\tNearest to so: device, frs, allotrope, believed, subgenres, something, entre, thea,\n",
      "\tNearest to the: their, its, his, a, this, each, our, some,\n",
      "\tNearest to in: during, within, at, between, on, around, and, throughout,\n",
      "\tNearest to into: from, through, within, via, with, after, between, around,\n",
      "\tNearest to their: its, his, her, the, your, our, whose, many,\n",
      "\tNearest to only: lodger, nephews, substitutes, lumi, cordite, procedures, still, dieu,\n",
      "\tNearest to its: their, his, her, the, our, hamming, your, my,\n",
      "\tNearest to three: four, five, six, eight, seven, two, nine, zero,\n",
      "\tNearest to had: has, have, were, was, having, will, never, became,\n",
      "\tNearest to united: galician, zum, tease, british, zinoviev, girdle, bitola, pore,\n",
      "\tNearest to his: their, her, its, the, your, my, s, whose,\n",
      "\tNearest to often: usually, still, generally, sometimes, commonly, being, frequently, widely,\n",
      "\tNearest to five: four, six, three, eight, seven, two, nine, zero,\n",
      "\tNearest to up: out, back, deep, them, off, down, away, disconnect,\n",
      "\tNearest to most: more, less, counterproductive, both, many, some, booth, engaged,\n",
      "step 32000\t171s\tAverage loss: 4.951744\n",
      "step 34000\t181s\tAverage loss: 5.082243\n",
      "step 36000\t191s\tAverage loss: 4.887568\n",
      "step 38000\t201s\tAverage loss: 4.863081\n",
      "step 40000\t212s\tAverage loss: 5.465642\n",
      "\tNearest to no: another, little, a, any, attested, said, this, officiate,\n",
      "\tNearest to so: medulla, ectopic, sip, liao, belladonna, allotrope, azathoth, multivibrator,\n",
      "\tNearest to the: their, its, his, a, our, each, this, your,\n",
      "\tNearest to in: during, within, throughout, between, despite, among, at, although,\n",
      "\tNearest to into: from, through, within, via, with, after, towards, under,\n",
      "\tNearest to their: its, his, her, the, your, our, whose, my,\n",
      "\tNearest to only: lodger, slurry, person, lumi, mnemonics, substitutes, taino, humans,\n",
      "\tNearest to its: their, his, her, the, our, your, hamming, my,\n",
      "\tNearest to three: six, four, five, two, seven, eight, nine, zero,\n",
      "\tNearest to had: has, have, were, having, was, during, when, never,\n",
      "\tNearest to united: british, galician, hawk, stomachs, zum, uk, reductionism, mailing,\n",
      "\tNearest to his: their, her, its, your, my, the, s, another,\n",
      "\tNearest to often: usually, generally, sometimes, still, commonly, now, typically, frequently,\n",
      "\tNearest to five: four, six, eight, seven, three, two, nine, zero,\n",
      "\tNearest to up: out, back, off, them, away, down, him, date,\n",
      "\tNearest to most: more, less, many, both, some, especially, use, very,\n",
      "step 42000\t222s\tAverage loss: 4.877806\n",
      "step 44000\t233s\tAverage loss: 4.864820\n",
      "step 46000\t243s\tAverage loss: 4.760992\n",
      "step 48000\t254s\tAverage loss: 4.636497\n",
      "step 50000\t265s\tAverage loss: 4.606251\n",
      "\tNearest to no: another, any, little, a, attested, this, teal, only,\n",
      "\tNearest to so: thus, patass, believed, if, sushi, device, thea, entre,\n",
      "\tNearest to the: their, its, his, our, a, your, any, this,\n",
      "\tNearest to in: during, within, at, throughout, between, although, on, despite,\n",
      "\tNearest to into: from, through, within, via, towards, around, with, back,\n",
      "\tNearest to their: its, his, her, our, your, the, whose, my,\n",
      "\tNearest to only: articulations, taino, both, even, still, lodger, cordite, karaca,\n",
      "\tNearest to its: their, his, her, the, our, your, whose, my,\n",
      "\tNearest to three: four, five, six, two, seven, eight, nine, zero,\n",
      "\tNearest to had: has, have, were, was, having, would, never, ever,\n",
      "\tNearest to united: galician, caribbean, stomachs, hyperfocal, wavell, lovelock, southern, british,\n",
      "\tNearest to his: her, their, its, your, my, the, our, s,\n",
      "\tNearest to often: usually, generally, sometimes, still, commonly, frequently, typically, now,\n",
      "\tNearest to five: six, four, eight, seven, three, nine, zero, two,\n",
      "\tNearest to up: out, back, off, down, them, away, him, lindisfarne,\n",
      "\tNearest to most: more, less, especially, both, many, some, use, particularly,\n",
      "step 52000\t276s\tAverage loss: 4.655197\n",
      "step 54000\t286s\tAverage loss: 4.561872\n",
      "step 56000\t297s\tAverage loss: 4.514009\n",
      "step 58000\t308s\tAverage loss: 5.177643\n",
      "step 60000\t319s\tAverage loss: 4.591501\n",
      "\tNearest to no: another, any, little, a, this, attested, criss, teal,\n",
      "\tNearest to so: thus, psi, grossing, f, sometimes, while, people, entre,\n",
      "\tNearest to the: its, their, his, our, this, each, a, any,\n",
      "\tNearest to in: during, within, throughout, under, at, despite, among, on,\n",
      "\tNearest to into: from, through, within, via, towards, under, between, around,\n",
      "\tNearest to their: its, his, her, the, many, our, my, your,\n",
      "\tNearest to only: both, still, actually, taino, lodger, even, frequently, lumi,\n",
      "\tNearest to its: their, his, her, the, our, your, whose, my,\n",
      "\tNearest to three: four, six, five, two, seven, eight, nine, one,\n",
      "\tNearest to had: has, have, was, having, were, ever, never, during,\n",
      "\tNearest to united: british, wavell, stomachs, galician, sovereign, andersson, hawk, sectional,\n",
      "\tNearest to his: her, its, their, your, my, the, our, whose,\n",
      "\tNearest to often: usually, generally, sometimes, still, commonly, frequently, typically, also,\n",
      "\tNearest to five: four, six, seven, eight, three, nine, zero, two,\n",
      "\tNearest to up: out, back, off, down, him, them, away, efforts,\n",
      "\tNearest to most: more, less, especially, use, mostly, particularly, some, both,\n",
      "step 62000\t331s\tAverage loss: 4.756212\n",
      "step 64000\t342s\tAverage loss: 4.605905\n",
      "step 66000\t352s\tAverage loss: 4.535759\n",
      "step 68000\t362s\tAverage loss: 4.411155\n",
      "step 70000\t373s\tAverage loss: 4.852087\n",
      "\tNearest to no: another, any, tech, a, this, per, gaye, strong,\n",
      "\tNearest to so: thus, sometimes, entre, grossing, too, something, miami, quite,\n",
      "\tNearest to the: their, its, his, our, whose, a, this, any,\n",
      "\tNearest to in: during, within, throughout, under, at, on, despite, between,\n",
      "\tNearest to into: via, from, through, within, towards, under, back, around,\n",
      "\tNearest to their: his, its, her, our, whose, your, the, my,\n",
      "\tNearest to only: both, therefore, otherwise, just, simply, actually, best, degenerative,\n",
      "\tNearest to its: their, his, her, the, our, whose, your, my,\n",
      "\tNearest to three: five, four, six, seven, eight, two, nine, zero,\n",
      "\tNearest to had: has, have, having, was, were, never, ever, since,\n",
      "\tNearest to united: british, wavell, stomachs, sovereign, preceding, specifically, cuisine, following,\n",
      "\tNearest to his: their, her, its, my, your, whose, our, the,\n",
      "\tNearest to often: usually, sometimes, generally, commonly, typically, still, frequently, now,\n",
      "\tNearest to five: four, six, seven, eight, three, nine, two, zero,\n",
      "\tNearest to up: out, off, back, down, him, them, away, behind,\n",
      "\tNearest to most: more, less, especially, particularly, quite, some, many, extremely,\n",
      "step 72000\t384s\tAverage loss: 4.403117\n",
      "step 74000\t395s\tAverage loss: 4.198362\n",
      "step 76000\t405s\tAverage loss: 4.415664\n",
      "step 78000\t416s\tAverage loss: 4.489708\n",
      "step 80000\t429s\tAverage loss: 4.317066\n",
      "\tNearest to no: another, any, little, a, strong, this, nine, some,\n",
      "\tNearest to so: thus, too, entre, sometimes, sushi, grossing, quite, therefore,\n",
      "\tNearest to the: their, its, his, our, whose, this, some, any,\n",
      "\tNearest to in: during, within, throughout, at, near, on, between, despite,\n",
      "\tNearest to into: through, from, via, within, around, under, across, back,\n",
      "\tNearest to their: its, his, her, our, whose, the, your, my,\n",
      "\tNearest to only: just, approximately, earliest, articulations, late, either, both, consubstantiation,\n",
      "\tNearest to its: their, his, her, our, the, whose, your, my,\n",
      "\tNearest to three: four, five, six, seven, two, eight, nine, one,\n",
      "\tNearest to had: has, have, having, were, was, never, gets, ever,\n",
      "\tNearest to united: british, specifically, stomachs, german, wavell, hawk, sovereign, both,\n",
      "\tNearest to his: her, their, its, my, your, whose, our, the,\n",
      "\tNearest to often: usually, sometimes, generally, commonly, typically, frequently, still, now,\n",
      "\tNearest to five: six, four, eight, seven, three, nine, two, zero,\n",
      "\tNearest to up: back, out, off, down, him, away, vagus, protect,\n",
      "\tNearest to most: less, more, many, especially, particularly, both, use, very,\n",
      "step 82000\t443s\tAverage loss: 4.103883\n",
      "step 84000\t458s\tAverage loss: 4.250638\n",
      "step 86000\t472s\tAverage loss: 4.255129\n",
      "step 88000\t485s\tAverage loss: 4.396056\n",
      "step 90000\t498s\tAverage loss: 4.255320\n",
      "\tNearest to no: another, any, little, strong, this, a, lombardo, juicy,\n",
      "\tNearest to so: sometimes, too, thus, therefore, something, perhaps, if, quite,\n",
      "\tNearest to the: their, its, his, our, whose, a, this, any,\n",
      "\tNearest to in: during, within, throughout, near, at, on, among, despite,\n",
      "\tNearest to into: through, via, from, within, towards, across, under, during,\n",
      "\tNearest to their: its, his, her, our, your, whose, my, the,\n",
      "\tNearest to only: just, approximately, earliest, late, last, roughly, therefore, meditations,\n",
      "\tNearest to its: their, his, her, our, the, whose, your, my,\n",
      "\tNearest to three: four, five, six, two, seven, eight, nine, zero,\n",
      "\tNearest to had: has, have, having, was, were, ever, never, gets,\n",
      "\tNearest to united: specifically, british, wavell, sovereign, hawk, zum, florida, financed,\n",
      "\tNearest to his: her, their, its, my, your, our, whose, the,\n",
      "\tNearest to often: usually, sometimes, generally, typically, commonly, frequently, still, now,\n",
      "\tNearest to five: six, four, seven, three, eight, nine, two, zero,\n",
      "\tNearest to up: off, back, out, down, them, together, him, away,\n",
      "\tNearest to most: more, less, many, especially, particularly, both, some, several,\n",
      "step 92000\t512s\tAverage loss: 4.169178\n",
      "step 94000\t526s\tAverage loss: 4.187094\n",
      "step 96000\t541s\tAverage loss: 4.161120\n",
      "step 98000\t556s\tAverage loss: 3.936359\n",
      "step 100000\t570s\tAverage loss: 3.920772\n",
      "\tNearest to no: another, any, little, this, additional, a, azimuth, nine,\n",
      "\tNearest to so: too, something, thus, sometimes, therefore, indeed, entre, perhaps,\n",
      "\tNearest to the: its, their, his, our, this, whose, your, any,\n",
      "\tNearest to in: during, within, near, throughout, at, despite, around, on,\n",
      "\tNearest to into: through, from, via, within, towards, across, during, under,\n",
      "\tNearest to their: his, its, her, our, your, whose, my, the,\n",
      "\tNearest to only: last, roughly, earliest, approximately, just, first, late, issue,\n",
      "\tNearest to its: their, his, her, our, the, whose, your, my,\n",
      "\tNearest to three: four, five, six, seven, eight, two, nine, zero,\n",
      "\tNearest to had: has, have, having, was, were, ever, never, enjoyed,\n",
      "\tNearest to united: meet, specifically, andersson, both, mjf, sovereign, osr, stomachs,\n",
      "\tNearest to his: her, their, its, my, your, our, whose, the,\n",
      "\tNearest to often: usually, sometimes, typically, generally, frequently, commonly, still, now,\n",
      "\tNearest to five: four, six, seven, eight, three, nine, two, zero,\n",
      "\tNearest to up: off, out, back, down, together, away, them, him,\n",
      "\tNearest to most: more, less, especially, particularly, many, both, some, quite,\n",
      "End.\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# EJECUCION CBOW\n",
    "##################\n",
    "\n",
    "num_steps = 100001\n",
    "loss_report_interval = 2000\n",
    "similarity_report_interval = 10000\n",
    "top_k = 8 # number of nearest neighbors a mostrar en el informe de similitud\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "sessCB = tf.Session(graph=graphCB_NCE)\n",
    "with sessCB as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  average_loss = 0\n",
    "\n",
    "  # iterar\n",
    "  for step in range(num_steps):\n",
    "    batch_data, batch_labels = generate_batch_cbow(batch_size, num_skips, skip_window)\n",
    "    feed_dict = {train_dataset : batch_data, train_labels : batch_labels}\n",
    "    _, L = session.run([optimizer, loss], feed_dict=feed_dict)\n",
    "    average_loss += L\n",
    "\n",
    "    # mostar la perdida media de un intervalo\n",
    "    if step % loss_report_interval == 0:\n",
    "      t2 = time.time()\n",
    "      if step > 0:\n",
    "        average_loss = average_loss / loss_report_interval\n",
    "      # The average loss is an estimate of the loss over the last loss_report_interval batches.\n",
    "      print('step %d\\t%ds\\tAverage loss: %f' % (step,t2-t1, average_loss))\n",
    "      average_loss = 0\n",
    "    \n",
    "    # mostrar la similitud alcanzada en un intervalo\n",
    "    # note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "    if step % similarity_report_interval == 0:\n",
    "      sim = similarity.eval() #tomar la variable calculada de similitud\n",
    "      for i in range(valid_size):\n",
    "        valid_word = reverse_dictionary[valid_examples[i]]\n",
    "        nearest = (-sim[i, :]).argsort()[1:top_k+1] # del vector de probabilidades de vecindad toma los 8 mayores\n",
    "        log = '\\tNearest to %s:' % valid_word\n",
    "        for k in range(top_k):\n",
    "          close_word = reverse_dictionary[nearest[k]]\n",
    "          log = '%s %s,' % (log, close_word)\n",
    "        print(log)\n",
    "        \n",
    "  final_cbow_embeddings = normalized_embeddings.eval() \n",
    "        #me quedo con las features finales que definen cada concepto de palabra\n",
    "  print(\"End.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vamos a dibujar cosas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID for \"but\" is 42\n",
      "computing neighbors...\n",
      "\tNearest 8 to \"but\": however, although, and, while, though, since, nevertheless, see,\n",
      "projecting and plotting...\n",
      "\tPCA variance ratio [ 0.25149943  0.1901748 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAANmCAYAAABZuXIoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120a1bc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID for \"woman\" is 1014\n",
      "computing neighbors...\n",
      "\tNearest 8 to \"woman\": man, person, people, son, female, speech, women, children,\n",
      "projecting and plotting...\n",
      "\tPCA variance ratio [ 0.23833531  0.205032  ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAANmCAYAAABZuXIoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABAB4Q7AACADvw/2uOtAs0djwcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1208332d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#CBOW\n",
    "show_nearest_embeddings_PCA('but',final_cbow_embeddings,area=8)\n",
    "show_nearest_embeddings_PCA('woman',final_cbow_embeddings,area=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "5_word2vec.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
